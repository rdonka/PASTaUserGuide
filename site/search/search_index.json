{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PASTa : P hotometry A nalysis and S ignal Processing T oolbox Welcome to the documentation site for PASTa ( P hotometry A nalysis and S ignal Processing T oolbox)! The PASTa protocol is an open source toolbox and protocol for the preparation, signal processing, and analysis of fiber photometry data. Fiber photometry is a rapidly growing technique to record real-time neural signaling in awake, behaving subjects. However, the processing and analysis of photometry data streams can be complicated, and there is wide divergence in methods across the field. While several open-source signal processing tools exist, platforms can be inflexible in accommodating experimental designs, lack consistency in signal peak detection, and be difficult to use for naive users. To remedy these challenges, we developed PASTa, an open-source MATLAB based toolbox and protocol for the processing and analysis of fiber photometry data. PASTa includes a full analysis pipeline from data preparation through signal processing and transient event detection. Default parameters were selected to provide users with a conservative starting place, with optional inputs to include other commonly used methods and techniques in the field. Additionally, the transient detection protocol adopts options for determining peak detection thresholds and pre-peak baselines to allow more reliable detection of events and characterization of transient kinetics. The pipeline is designed to process multiple sessions at once, automating data processing, analysis, and plot creation to ensure application consistency across experimental sessions. While operating through MATLAB, the code is annotated to be readable, accessible for new users, and adaptable. Here you'll find a detailed user guide for each stage of PASTa, including installation instructions, detailed guidelines for each stage of the signal processing and analysis pipeline, example analyses, and additional details on function inputs and usage to support the documenation available within each function. Navigating the PASTa Repository and Documentation The PASTa code is openly available on GitHub . The toolbox is also available as a toolbox through MATLAB File Exchange . This user guide contains detailed documentation, instructions for function use, and troubleshooting tips. Getting Started The Getting Started page includes quick start instructions and installation tips. This is a great place to start if you haven't previously downloaded or implemented the PASTa Protocol on your device. User Guide The User Guide page includes detailed instructions and examples for every step of the protocol, including Data Preparation , Signal Processing , and Transient Analysis . This is the best place to start for new users. Each page will walk you through each step, with information about the reccomended settings and any defaults built in to the protocol. The guide also includes examples of each step with fiber photometry recordings with three sensors capturing mesolimbic dopamine dynamics to help users gain an intuition for what each phase of the process is doing to the data streams. Function Documentation For using and troubleshooting individual functions, the Function Documentation page includes even more details about the use of each function in the toolbox, including notes and suggestions for troubleshooting errors. Detailed documentation is also commented in to each function in the source code - just view the help window or open the function source file in MATLAB to read. Example Analyses Additionally, to provide an example of the full pipeline, the Example Analyses page provides users with full examples of experimental analyses. All files needed to perform the example analyses are available for download so users can walk through each step in MATLAB on their own devices to ensure that installation and set up were sucessful, and view outputs of a validated script. Please feel free to reach out with questions, additional functionality requests, and other thoughts! Our contact information is provided here .","title":"Home"},{"location":"#pasta-photometry-analysis-and-signal-processing-toolbox","text":"Welcome to the documentation site for PASTa ( P hotometry A nalysis and S ignal Processing T oolbox)! The PASTa protocol is an open source toolbox and protocol for the preparation, signal processing, and analysis of fiber photometry data. Fiber photometry is a rapidly growing technique to record real-time neural signaling in awake, behaving subjects. However, the processing and analysis of photometry data streams can be complicated, and there is wide divergence in methods across the field. While several open-source signal processing tools exist, platforms can be inflexible in accommodating experimental designs, lack consistency in signal peak detection, and be difficult to use for naive users. To remedy these challenges, we developed PASTa, an open-source MATLAB based toolbox and protocol for the processing and analysis of fiber photometry data. PASTa includes a full analysis pipeline from data preparation through signal processing and transient event detection. Default parameters were selected to provide users with a conservative starting place, with optional inputs to include other commonly used methods and techniques in the field. Additionally, the transient detection protocol adopts options for determining peak detection thresholds and pre-peak baselines to allow more reliable detection of events and characterization of transient kinetics. The pipeline is designed to process multiple sessions at once, automating data processing, analysis, and plot creation to ensure application consistency across experimental sessions. While operating through MATLAB, the code is annotated to be readable, accessible for new users, and adaptable. Here you'll find a detailed user guide for each stage of PASTa, including installation instructions, detailed guidelines for each stage of the signal processing and analysis pipeline, example analyses, and additional details on function inputs and usage to support the documenation available within each function.","title":"PASTa: Photometry Analysis and Signal Processing Toolbox"},{"location":"#navigating-the-pasta-repository-and-documentation","text":"The PASTa code is openly available on GitHub . The toolbox is also available as a toolbox through MATLAB File Exchange . This user guide contains detailed documentation, instructions for function use, and troubleshooting tips.","title":"Navigating the PASTa Repository and Documentation"},{"location":"#getting-started","text":"The Getting Started page includes quick start instructions and installation tips. This is a great place to start if you haven't previously downloaded or implemented the PASTa Protocol on your device.","title":"Getting Started"},{"location":"#user-guide","text":"The User Guide page includes detailed instructions and examples for every step of the protocol, including Data Preparation , Signal Processing , and Transient Analysis . This is the best place to start for new users. Each page will walk you through each step, with information about the reccomended settings and any defaults built in to the protocol. The guide also includes examples of each step with fiber photometry recordings with three sensors capturing mesolimbic dopamine dynamics to help users gain an intuition for what each phase of the process is doing to the data streams.","title":"User Guide"},{"location":"#function-documentation","text":"For using and troubleshooting individual functions, the Function Documentation page includes even more details about the use of each function in the toolbox, including notes and suggestions for troubleshooting errors. Detailed documentation is also commented in to each function in the source code - just view the help window or open the function source file in MATLAB to read.","title":"Function Documentation"},{"location":"#example-analyses","text":"Additionally, to provide an example of the full pipeline, the Example Analyses page provides users with full examples of experimental analyses. All files needed to perform the example analyses are available for download so users can walk through each step in MATLAB on their own devices to ensure that installation and set up were sucessful, and view outputs of a validated script. Please feel free to reach out with questions, additional functionality requests, and other thoughts! Our contact information is provided here .","title":"Example Analyses"},{"location":"contactus/","text":"Contact Us PASTa is actively managed by our team, and updates will be continual to add new features, address user feedback, and adapt to the every changing experimental landscape. For more information, or to request new features, please feel free to reach out! For feature requests, help with troubleshooting, and general discussion, please make use of our discussion forums on GitHub. This will allow us to build an open resource center with comments and feedback from all users. Visit the forums under the tab Discussions on our GitHub . To contact our team directly, email us at pastaprotocol@gmail.com","title":"Contact Us"},{"location":"contactus/#contact-us","text":"PASTa is actively managed by our team, and updates will be continual to add new features, address user feedback, and adapt to the every changing experimental landscape. For more information, or to request new features, please feel free to reach out! For feature requests, help with troubleshooting, and general discussion, please make use of our discussion forums on GitHub. This will allow us to build an open resource center with comments and feedback from all users. Visit the forums under the tab Discussions on our GitHub . To contact our team directly, email us at pastaprotocol@gmail.com","title":"Contact Us"},{"location":"exampleanalyses/","text":"To help users get started with the PASTa Protocol, here some example analyses are included with raw data to walk users through each step of the process. Injection Transients This example is of whole session transient analysis to determine changes in dopaminergic cell body GCaMP6f transients following morphine injection. The example analysis script is located in the PASTa repository under 'Example Analyses\\main_ExampleAnalysis_Transients.m'. Data Summary Example data are provided from two subjects. Each subject has two fiber photometry sessions conducted on consecutive days: saline and morphine (10mg/kg). Each session consists of a fifteen minute baseline, an i.p. injection, and a 60 minute post-injection recording period. Fiber photometry data were recorded using Tucker Davis Technologies RZ5 processor, with a 465nm excitation wavelength ('signal') and a 405nm isosbestic control wavelength ('background'). Injection start and end time points are marked by epocs sent through Med Associates equipment and stored by Synapse as time stamps. Data are available for download from Box under Example Analyses . The subfolder Injection Transients is prepared for the analysis, containing the file and subject keys, as well as folders created for extracted data, analysis, and figure outputs. Raw data blocks collected via Synapse (Tucker Davis Technologies) are nested in the Raw Data folder. NOTE FOR MAC USERS: A Mac compatible version of the file key is included in the Example Analyses folder. In your main analysis script, make sure to update the file name to 'FileKey_ExampleAnalysis_MorphineTransients_MAC.csv' . If you have any questions or run into problems accessing the files, please feel free to contact us . Data Preparation The first section of the script sets up paths and analysis key inputs. To enable users to switch computers easily, paths are created without the computer and user specific portion. The computer user specific portion of the path is input to the variable computeruserpath and appended to subsequently needed paths. To access files and functions, paths need to be added to MATLAB via the addpath function. genpath is used within addpath to ensure folders and subfolders at the input path are added. Finally, the names of created Subject and File Keys are added to variables subjectkeyname and filekeyname . These keys contain the session specific and subject specific information needed to load the data and analyze the results. For details on keys, see the user guide section on Data Preparation . The keys are loaded using the function loadKeys to join the subject specific data to the session specific information contained in the file key. Paths to raw data blocks and extracted output locations are added to string arrays, which are input to the function extractTDTdata . extractTDTdata first extracts the raw data for each file into a data structure, then saves the MATLAB data structure to extracted output location. Extracted structures for each file are then loaded by the function loadKeydata . After data are loaded, excess samples before the start of the program and after the end of the post-injection period are cropped from the streams. First, session start and end indices are prepared for each file. These indices are input to the function cropFPdata , which removes the excess samples from the signal and background streams, and adjusts the injection and session start time stamp epocs. Signal Processing To control for motion artifacts and photobleaching, the 405 nm channel (baq) is subtracted from the 465 nm channel (sig) with the function subtractFPdata . First, this function scales the background stream to the signal stream. After scaling, the background is subtracted from the signal in the time domain, and filtered with a Butterworth bandpass filter to remove the DC offset as well as high frequency noise (frequencies outside the range of biological interest). The scaling factor ( 'baqscalingfactor' ), subtracted signal ( 'sigsub' ), filtered signal ( 'sigfilt' ) are added to the data structure. Raw, subtracted, and filtered streams for the whole session are visualized and saved to the output folder 'Figures' . Additionally, frequency magnitude plots of the FFTs of the raw, scaled, subtracted, and filtered streams are generated and saved to the 'Figures' folder. After subtraction, the filtered signal is normalized. To normalize to the entire session, the function normSession is called, outputting the z scored signal streams to 'sigfiltz_normsession' . To normalize to pre injection baseline, the function normBaseline is called, which uses the pre-injection period to normalize the entire session, outputting the z scored streams to 'sigfiltz_normsession' . Finally, a for loop is used to create streams with the injection time period removed. For details on the signal processing functions and methods, see the user guide section on Signal Processing . Transient Detection To identify transient events, the findSessionTransients functions are used. These functions detect relevant transients in the normalized data stream based on an amplitude inclusiong criterion (eg, 3SD amplitude) relative to baseline. Multiple baseline options exist - see function documentation for findSessionTransients_blmean , findSessionTransients_blmin , and findSessionTransients_localmin for more specific details. After detection, transients are quantified by frequency, amplitude, half height rise time, half height fall time, half height width, and half height AUC. After detection and quantification, transients are binned into 5 minute increments. To do so, the number of samples per bin is identified and added to the data structure. The function binSessionTransients identifies and adds the bin of each transient event to the transientquantificiation table. Individual bins with identified transients are plotted and figures are saved to the folder. To export the transient events for statistical analysis, the table for each file is appended into the table alltransients which is output as a csv to the location specified by analysispath. Relevant experimental variables (subject ID, treatment number, and injection type) are appended to the table.","title":"Example Analyses"},{"location":"exampleanalyses/#injection-transients","text":"This example is of whole session transient analysis to determine changes in dopaminergic cell body GCaMP6f transients following morphine injection. The example analysis script is located in the PASTa repository under 'Example Analyses\\main_ExampleAnalysis_Transients.m'.","title":"Injection Transients"},{"location":"exampleanalyses/#data-summary","text":"Example data are provided from two subjects. Each subject has two fiber photometry sessions conducted on consecutive days: saline and morphine (10mg/kg). Each session consists of a fifteen minute baseline, an i.p. injection, and a 60 minute post-injection recording period. Fiber photometry data were recorded using Tucker Davis Technologies RZ5 processor, with a 465nm excitation wavelength ('signal') and a 405nm isosbestic control wavelength ('background'). Injection start and end time points are marked by epocs sent through Med Associates equipment and stored by Synapse as time stamps. Data are available for download from Box under Example Analyses . The subfolder Injection Transients is prepared for the analysis, containing the file and subject keys, as well as folders created for extracted data, analysis, and figure outputs. Raw data blocks collected via Synapse (Tucker Davis Technologies) are nested in the Raw Data folder. NOTE FOR MAC USERS: A Mac compatible version of the file key is included in the Example Analyses folder. In your main analysis script, make sure to update the file name to 'FileKey_ExampleAnalysis_MorphineTransients_MAC.csv' . If you have any questions or run into problems accessing the files, please feel free to contact us .","title":"Data Summary"},{"location":"exampleanalyses/#data-preparation","text":"The first section of the script sets up paths and analysis key inputs. To enable users to switch computers easily, paths are created without the computer and user specific portion. The computer user specific portion of the path is input to the variable computeruserpath and appended to subsequently needed paths. To access files and functions, paths need to be added to MATLAB via the addpath function. genpath is used within addpath to ensure folders and subfolders at the input path are added. Finally, the names of created Subject and File Keys are added to variables subjectkeyname and filekeyname . These keys contain the session specific and subject specific information needed to load the data and analyze the results. For details on keys, see the user guide section on Data Preparation . The keys are loaded using the function loadKeys to join the subject specific data to the session specific information contained in the file key. Paths to raw data blocks and extracted output locations are added to string arrays, which are input to the function extractTDTdata . extractTDTdata first extracts the raw data for each file into a data structure, then saves the MATLAB data structure to extracted output location. Extracted structures for each file are then loaded by the function loadKeydata . After data are loaded, excess samples before the start of the program and after the end of the post-injection period are cropped from the streams. First, session start and end indices are prepared for each file. These indices are input to the function cropFPdata , which removes the excess samples from the signal and background streams, and adjusts the injection and session start time stamp epocs.","title":"Data Preparation"},{"location":"exampleanalyses/#signal-processing","text":"To control for motion artifacts and photobleaching, the 405 nm channel (baq) is subtracted from the 465 nm channel (sig) with the function subtractFPdata . First, this function scales the background stream to the signal stream. After scaling, the background is subtracted from the signal in the time domain, and filtered with a Butterworth bandpass filter to remove the DC offset as well as high frequency noise (frequencies outside the range of biological interest). The scaling factor ( 'baqscalingfactor' ), subtracted signal ( 'sigsub' ), filtered signal ( 'sigfilt' ) are added to the data structure. Raw, subtracted, and filtered streams for the whole session are visualized and saved to the output folder 'Figures' . Additionally, frequency magnitude plots of the FFTs of the raw, scaled, subtracted, and filtered streams are generated and saved to the 'Figures' folder. After subtraction, the filtered signal is normalized. To normalize to the entire session, the function normSession is called, outputting the z scored signal streams to 'sigfiltz_normsession' . To normalize to pre injection baseline, the function normBaseline is called, which uses the pre-injection period to normalize the entire session, outputting the z scored streams to 'sigfiltz_normsession' . Finally, a for loop is used to create streams with the injection time period removed. For details on the signal processing functions and methods, see the user guide section on Signal Processing .","title":"Signal Processing"},{"location":"exampleanalyses/#transient-detection","text":"To identify transient events, the findSessionTransients functions are used. These functions detect relevant transients in the normalized data stream based on an amplitude inclusiong criterion (eg, 3SD amplitude) relative to baseline. Multiple baseline options exist - see function documentation for findSessionTransients_blmean , findSessionTransients_blmin , and findSessionTransients_localmin for more specific details. After detection, transients are quantified by frequency, amplitude, half height rise time, half height fall time, half height width, and half height AUC. After detection and quantification, transients are binned into 5 minute increments. To do so, the number of samples per bin is identified and added to the data structure. The function binSessionTransients identifies and adds the bin of each transient event to the transientquantificiation table. Individual bins with identified transients are plotted and figures are saved to the folder. To export the transient events for statistical analysis, the table for each file is appended into the table alltransients which is output as a csv to the location specified by analysispath. Relevant experimental variables (subject ID, treatment number, and injection type) are appended to the table.","title":"Transient Detection"},{"location":"functiondocumentation/","text":"Function Documentation Overview This page contains additional documentation for each function within PASTa, as well as examples of inputs. Data Preparation Functions This set of functions is used to prepare raw photometry data, match it with experimental metadata, and load data into a structure in MATLAB. Functions are provided to handle data collected via TDT equipment and software Synapse, or a generic file structure with data streams saved to CSV files. loadKeys Combines subject key and file key into a data structure, and appends the provided computeruserpath to the paths in the file key. INPUTS: COMPUTERUSERPATH: A variable containing the unique portion of the file explorer path for the users specific computer. For example, 'C:\\Users\\rmdon\\'. Make sure the computeruserpath ends in a forward slash. SUBJECTKEYNAME: A variable containing a string with the name of the subject key csv file for the experiment (see \"3. Data Analysis Pipeline\" for more details). To omit a subject key and only load in the file key, set subjectkeyname = \"\". FILEKEYNAME: A variable containing a string with the name of the file key csv file for the experiment (see \"3. Data Analysis Pipeline\" for more details). OUTPUTS: EXPERIMENTKEY: A data structure called \"experimentkey\" that includes the joined file key and subject key with the computer user path appended to raw and extracted folder paths. EXAMPLE: computeruserpath = 'C:\\Users\\MYNAME\\'; % Computer specific portion of file navigation paths subjectkeyname = 'Subject Key.csv'; % Name of csv file containing subject information; set to '' if not using a subject key filekeyname = 'File Key.csv'; % Name of csv file containing session information, raw data folder names, and paths [experimentkey] = loadKeys(computeruserpath, subjectkeyname, filekeyname); % Load keys into a data structure called experimentkey NOTES: FILEKEY must contain at a minimum the fields Subject , RawFolderPath , and ExtractedFolderPath . SUBJECTKEY must contain at a minimum the field Subject Folder paths must end with a slash. The subject and file keys are joined based on Subject ID. Subject key must contain every subjects in the file key. If there is a mismatch, you will receive an error message that the right table does not contain all the key variables that are in the left table. The error message will display the unique subject IDs present in each key so you can determine where the mismatch occurred. Fields in subject and file key must be named uniquely. The only field that should be named the same in both keys is Subject. extractTDTdata This function is used to extract TDT data from saved blocks recorded via the software Synapse . For each block, extractTDTdata calls the function \"TDTbin2mat\" (TDT, 2019) and inputs the RawFolderPath to extract fiber photometry data recorded with Synapse. Extracted blocks are parsed it into a single data structure containing all fields, streams, and epocs. Extracted signal streams are trimmed to remove the first 5 seconds by default (trimming can be adjusted if desired). The function will identify the signal channel by matching the names in the input SIGSTREAMNAMES and the control channel by matching the names in the input BAQSTREAMNAMES. The name inputs can include a list of stream names if channel naming conventions vary by rig. Each block is saved as a separate data structure in a '.mat' file at the location specified by the inputs in extractedfolderpaths. INPUTS: RAWFOLDERPATHS: a string array containing the paths to the folder location of the raw data blocks to be extracted. The string array should contain one column with each full path in a separate row. EXTRACTEDFOLDERPATHS: a string array containing the paths to the folder location in which to save the extracted MatLab structs for each block to be extracted. The string array should contain one column with each full path in a separate row. SIGSTREAMNAMES: A cell array containing strings with the names of the streams to be treated as signal. Note that only one stream per file can be treated as signal. If different files have different stream names, include all stream names in the cell array. BAQSTREAMNAMES: A cell array containing strings with the names of the streams to be treated as background. Note that only one stream per file can be treated as background. If different files have different stream names, include all stream names in the cell array. OPTIONAL INPUTS: TRIM: the number of seconds to remove on either end of the data streams. If not specified, defaults to 5 seconds. SKIPEXISTING: A binary variable containing a 0 if pre-existing extracted blocks should be re-extracted or a 1 if pre-existing extracted blocks should be skipped. This allows the user to toggle whether or not to extract every block, or only blocks that have not previously been extracted. If not specified, defaults to 1 (skip previously extracted blocks). OUTPUTS: Saved .mat data structures for each block in the location specified by extractedfolderpaths. EXAMPLE - DEFAULT: sigstreamnames = {'x65A', '465A'}; % All names of signal streams across files baqstreamnames = {'x05A', '405A'}; % All names of background streams across files rawfolderpaths = string({experimentkey.RawFolderPath})'; % Create string array of raw folder paths extractedfolderpaths = string({experimentkey.ExtractedFolderPath})'; % Create string array of extracted folder paths extractTDTdata(rawfolderpaths,extractedfolderpaths,sigstreamnames,baqstreamnames); % extract data EXAMPLE - MANUALLY SPECIFIED TRIM AND SKIPEXISTING: trim = 3; skipexisting = 0; sigstreamnames = {'x65A', '465A'}; % All names of signal streams across files baqstreamnames = {'x05A', '405A'}; % All names of background streams across files rawfolderpaths = string({experimentkey.RawFolderPath})'; % Create string array of raw folder paths' extractedfolderpaths = string({experimentkey.ExtractedFolderPath})'; % Create string array of extracted folder paths' extractTDTdata(rawfolderpaths,extractedfolderpaths,sigstreamnames,baqstreamnames,'trim',trim,'skipexisting',skipexisting); % extract data loadTDTdata For use with previously extracted data collect with TDT equipment and software Synapse. loadTDTData loads previously extracted .mat data blocks into a data structure for further analysis. Each block is one row. The input experiment key must include at a minimum the extracted folder path location of the block. Any additional information about the subject and session in the experiment key will be matched to the extracted data. INPUTS: EXPERIMENTKEY: A prepared data structure with at minimum the ExtractedFolderPath containing the full path to the individual session data structures to be loaded. The EXPERIMENTKEY can be prepared with the LOADKEYS function. OUTPUTS: DATA: the input data structure with each individual extracted block added by row. EXAMPLE: [rawdata] = loadKeydata(experimentkey); % Load data based on the experiment key into the structure 'rawdata' loadCSVdata For use with data collected and stored to a general file structure. coming soon cropFPdata Used to crop data streams to remove portions that are not to be included in analysis (such as the the first two minutes of the session, or the first samples before a hardware control program is initiated). Crops all specified data streams from the index in cropstart to the index in cropend, and adjusts epocs by the amount cropped by cropstart. Users must pre-prepare the crop start and end indexes to specify as inputs for the function. INPUTS: DATA: A data frame containing at least the specified input fields. CROPSTART: The location to start cropping at. CROPEND: The location to end cropping at. WHICHSTREAMS: A cell array containing the names of all the streams to be cropped. OPTIONAL INPUTS: WHICHEPOCS: A cell array containing the names of all the epocs to be adjusted due to cropping - subtract the (start loc - 1) from the epoc. OUTPUTS: DATA: The data structure with the specified data stream containing the cropped data. EXAMPLE: cropstart = 'sessionstart'; % name of field with session start index cropend = 'sessionend'; % name of field with session end index whichstreams = {'sig', 'baq','time'}; % which streams to crop whichepocs = {'injt','sess'}; % which epocs to adjust to maintain relative position [data] = cropFPdata(rawdata,cropstart,cropend, whichstreams,whichepocs); % Output cropped data into new structure called data Signal Processing Functions subtractFPdata Used to subtract the background photometry stream (eg, 405nm) from the signal stream (eg, 465nm), convert the subtracted signal to delta F/f, and apply a filter to denoise the output. Users must input the data structure with the raw data, the names of the fields containing the signal and background streams, and the sampling rate of the collected data. INPUTS: DATA: A data frame containing at least the specified input fields. SIGFIELD: The name (string) of the field containing the signal stream. BAQFIELD: The name (string) of the field containing the background stream. WHICHFS: The name (string) of the field containing the sampling rate of the raw data collection in Hz. OPTIONAL INPUTS: BAQSCALINGTYPE: A string to specify the type of background scaling to apply. Options are 'frequency', 'sigmean', 'OLS', 'detrendOLS', 'smoothedOLS', or 'IRLS'. Default: 'frequency'. 'frequency': Scales the background to the signal channel based on ratio of specified frequency bands in the FFT (frequency domain) of the channels. 'sigmean': Scales the background to the signal channel based on the ratio of the mean of the signal to the mean of the background (time domain). 'OLS': Uses ordinary least-squares regression to generate scaled background. 'detrendOLS': Removes the linear trend from signal and background streams prior to using ordinary least-squares regression to generate scaled background. 'smoothedOLS': Applies lowess smoothing to the signal and background streams prior to using ordinary least-squares regression to generate scaled background. 'IRLS': Uses iteratively reweighted least squares regression to generate scaled background. BAQSCALINGFREQ: Only used with 'frequency' scaling. Numeric frequency (Hz) threshold for scaling the background to signal channel. Frequencies above this value will be included in the scaling factor determination. Default: 10 Hz. BAQSCALINGPERC: Only used with 'frequency' and 'sigmean' scaling. Adjusts the background scaling factor to be a percent of the derived scaling factor value. Default: 1 (100%). SUBTRACTIONOUTPUT: Output type for the subtracted data. Default: 'dff' 'dff': Outputs subtracted signal as delta F/F. 'df': Outputs subtracted signal as delta F. FILTERTYPE: A string to specify the type of filter to apply after subtraction. Default: 'bandpass'. 'nofilter': No filter will be applied. 'bandpass': A bandpass filter will be applied. 'highpass': Only the high pass filter will be applied. 'lowpass': Only the low pass filter will be applied. PADDING: Defaults to 1, which applies padding. Padding takes the first 10% of the stream, flips it, and appends it to the data before filtering. Appended data is trimmed after filtration. Set to 0 to turn off padding of data streams. Default: 1. PADDINGPERC: Percent of data length to use to determine the number of samples to be appended to the beginning and end of data in padding. Set to minimum 10%. Default: 0.1 (10%). FILTERORDER: The order to be used for the chosen butterworth filter. Default: 3. HIGHPASSCUTOFF: The cutoff frequency (hz) to be used for the high pass butterworth filter. Default: 2.2860. LOWPASSCUTOFF: The cutoff to be used for the low pass butterworth filter. Default: 0.0051. NOTE: 'bandpass' applies both the high and low cutoffs to design the filter. SUPRESSDISP: If set to anything other than 0, this will suppress the command window displays. Default: 0. OUTPUTS: DATA: The original data structure with added fields with the scaled background ('baq_scaled'), subtracted signal ('sigsub'), and subtracted and filtered signal ('sigfilt'). All inputs and defaults will be added to the data structure under the field 'inputs'. NOTE: If using BAQSCALINGMETHOD 'detrendOLS' , additional fields containing the detrended signal and background ('sig_detrend' and 'baq_detrend') will be added to the data frame. If using BAQSCALINGMETHOD 'smoothedOLS' , additional fields containing the smoothed signal and background ('sig_smoothed' and 'baq_smoothed') will be added to the data frame. EXAMPLE - DEFAULT: sigfield = 'sig'; baqfield = 'baq'; fs = 1017; data = subtractFPdata(data,sigfield,baqfield,fs); EXAMPLE - Frequency Scaling with 20Hz Threshold and Highpass Filter Only: sigfield = 'sig'; baqfield = 'baq'; fs = 1017; data = subtractFPdata(data,sigfield,baqfield,fs,'baqscalingfreq',20,'filtertype,'highpass'); normSession Used to normalize the subtracted and filtered signal stream to Z score based on the whole session mean and standard deviation. INPUTS: DATA: A data frame containing at least the stream specified to be normalized. WHICHSTREAM: A string with the name of the field containing the stream to be normalized. OUTPUTS: DATA: The data structure with the field 'data.WHICHSTREAMz_normsession' containing the whole session normalized signal added. EXAMPLE: [data] = normSession(data,'sigfilt'); % Outputs whole session z score normBaseline Used to normalize the subtracted and filtered signal stream to Z score based on the a session baseline mean and standard deviation. INPUTS: DATA: A data frame containing at least the stream specified to be normalized. WHICHSTREAM: A string with the name of the field containing the stream to be normalized. WHICHBLSTART: A string with the name of the field containing the index of the start of the baseline period. WHICHBLEND: A string with the name of the field containing the index of the end of the baseline period. OUTPUTS: DATA: The data structure with the field 'data.WHICHSTREAMz_normbaseline' containing the full stream normalized to baseline added. EXAMPLE: % Prepare baseline start and end indices for eachfile = 1:length(data) % prepare indexes for baseline period start and end data(eachfile).BLstart = 1; data(eachfile).BLend = data(eachfile).injt(1); end % Normalize filtered signal to session baseline mean and SD [data] = normBaseline(data,'sigfilt','BLstart','BLend'); preparestreamFFT Helper function to take the FFT of a data stream and output the magnitudes and corresponding frequencies for analysis, plotting, and diagnostics. This function is called by the plot function plotFFTs but can also be used to prepare FFTs for each stream of data for all sessions with use in a for loop. INPUTS: STREAMDATA: An array containing the values from a single collected data stream. FS: The sampling rate of the data stream. OUTPUTS: STREAMFFT: An array containing the prepared FFT magnitudes of the input stream. STREAMF: An array containing the corresponding frequencies to the prepared FFT magnitudes in STREAMFFT. EXAMPLE OF SINGLE SESSION SIGNAL: [streamFFT,streamF] = preparestreamFFT(data(1).sig,data(eachfile).fs); EXAMPLE OF ALL SESSIONS AND STREAMS: %% Prepare FFTs of all streams streams = {'sig', 'baq', 'baq_scaled','sigsub', 'sigfilt'}; % Frequency scaled background for eachfile = 1:length(data) for eachstream = 1:length(streams) streamname = char(streams(eachstream)); [streamFFT,streamF] = preparestreamFFT(data(eachfile).(streamname),data(eachfile).fs); data(eachfile).(append(streamname,'FFT')) = streamFFT; data(eachfile).(append(streamname,'F')) = streamF; end end Transient Detection and Quantification Functions findSessionTransients Main function to detect and quantify transient events in whole session data streams. Use of this main function will set default values for parameters not specific as optional inputs. Users must input the raw data structure containing the data stream, a field with threshold values for transient inclusion, and the sampling rate of the stream. Optional inputs can be specified to modify transient detection parameters, but defaults will be applied if not specified. INPUTS: DATA: This is a structure that contains at least the data stream you want to analyze, a field with the threshold values, and a field with the sampling rate of the data stream. WHICHBLTYPE: A string with the type of pre-transient baseline to use for amplitude inclusion and quantification. 'blmean': Pre-transient baselines are set to the mean of the pre-transient window. 'blmin': Pre-transient baselines are set to the minimum value within the pre-transient window. 'localmin': Pre-transient baselines are set to the local minimum directly preceding the transient within the baseline window. WHICHSTREAM: The name (string) of the field containing the stream to be analyzed for transients. WHICHTHRESHOLD: The name (string) of the field containing the prepared numeric threshold values for each stream. For example, 'threshold_3SD'. WHICHFS: The name (string) of the field containing the sampling rate of the raw data collection in Hz. OPTIONAL INPUTS: PREMINSTARTMS: Number of millseconds pre-transient to use as the start of the baseline window. Default: 800 PREMINENDMS: Number of millseconds pre-transient to use as the end of the baseline window. Default: 100 POSTTRANSIENTMS: Number of millseconds post-transient to use for the post peak baseline and trimmed data output. Default: 2000 QUANTIFICATIONHEIGHT: The height at which to characterize rise time, fall time, peak width, and AUC. Must be a number between 0 and 1. Default: 0.5 OUTPUTTRANSIENTDATA: Set to 1 to output cut data streams for each transient event for further analysis or plotting. Set to 0 to skip. Default: 1 OUTPUTS: DATA: The original data structure with sessiontransients_WHICHBLTYPE_THRESHOLDLABEL added in. For more details on individual variables, see the PASTa user guide page Transient Detection . The output contains four nested tables: INPUTS: Includes all required and optional inputs. If optional inputs are not specified, defaults will be applied. TRANSIENTQUANTIFICATION: Includes the quantified variables for each transient, including amplitude, rise time, fall time, width, and AUC. TRANSIENTSTREAMLOCS: Pre-transient baseline, transient peak, rise, and fall locations for each transient to match the cut transient stream data. _TRANSIENTSTREAMDATA: Cut data stream from baseline start to the end of the post-transient period for each transient event. NOTES: Threshold values should be calculated before using the findSessionTransients functions. Typically thresholds are set to 2-3 SDs. If the input data stream is Z scored, this can be the actual SD threshold number. If the input data stream is not Z scored, find the corresponding value to 2-3 SDs for each subject. For transient data outputs, each transient is in a separate row. If OUTPUTTRANSIENTDATA is set to anything other than 1, the TRANSIENTSTREAMLOCS and TRANSIENTSTREAMDATA tables will be skipped and not included in the output. EXAMPLE: % Prepare thresholds - since Z scored streams will be analyzed, input threshold as the desired SD. for eachfile = 1:length(data) data(eachfile).threshold3SD = 3; end % Find session transients based on pre-peak baseline window minimum [data] = findSessionTransients(data,'blmin','sigfiltz_normsession_trimmed','threshold3SD','fs'); % Find session transients based on pre-peak baseline window mean [data] = findSessionTransients(data,'blmean','sigfiltz_normsession_trimmed','threshold3SD','fs','preminstartms',600); % Find session transients based on pre-peak local minimum (last minumum before the peak in the baseline window) [data] = findSessionTransients(data,'localmin','sigfiltz_normsession_trimmed','threshold3SD','fs','quantificationheight',0.25); findSessionTransients_blmean Sub function to detect and quantify transient events in whole session data streams. Transient baselines are defined as the mean of the pre-transient baseline window. This function is called by the main function findSessionTransients , which sets default parameters for transient detection and quantification. If called outside the main function, users must specify all input values manually. INPUTS: DATA: This is a structure that contains at least the data stream you want to analyze, a field with the threshold values, and a field with the sampling rate of the data stream. WHICHSTREAM: The name (string) of the field containing the stream to be analyzed for transients. WHICHTHRESHOLD: The name (string) of the field containing the prepared numeric threshold values for each stream. For example, 'threshold_3SD'. WHICHFS: The name (string) of the field containing the sampling rate of the raw data collection in Hz. PREMINSTARTMS: Number of millseconds pre-transient to use as the start of the baseline window. Reccomended value: 800 PREMINENDMS: Number of millseconds pre-transient to use as the end of the baseline window. Reccomended value: 100 POSTTRANSIENTMS: Number of millseconds post-transient to use for the post peak baseline and trimmed data output. Reccomended value: 2000 QUANTIFICATIONHEIGHT: The height at which to characterize rise time, fall time, peak width, and AUC. Must be a number between 0 and 1. Reccomended value: 0.5 OUTPUTTRANSIENTDATA: Set to 1 to output cut data streams for each transient event for further analysis or plotting. Set to 0 to skip. Reccomended value: 1 OUTPUTS: DATA: The original data structure with sessiontransients_blmean_THRESHOLDLABEL added in. For more details on individual variables, see the PASTa user guide page Transient Detection . The output contains four nested tables: INPUTS: Includes all function inputs. TRANSIENTQUANTIFICATION: Includes the quantified variables for each transient, including amplitude, rise time, fall time, width, and AUC. TRANSIENTSTREAMLOCS: Pre-transient baseline start, pre-transient baseline end, transient peak, rise, and fall locations for each transient to match the cut transient stream data. _TRANSIENTSTREAMDATA: Cut data stream from baseline window start to the end of the post-transient period for each transient event. NOTES: If called outside the main findSessionTransients function, note that users will have to input all parameters manually and no defaults will be applied. As for the main function, threshold values should be calculated before using the findSessionTransients functions. Typically thresholds are set to 2-3 SDs. If the input data stream is Z scored, this can be the actual SD threshold number. If the input data stream is not Z scored, find the corresponding value to 2-3 SDs for each subject. For transient data outputs, each transient is in a separate row. If OUTPUTTRANSIENTDATA is set to anything other than 1, the TRANSIENTSTREAMLOCS and TRANSIENTSTREAMDATA tables will be skipped and not included in the output. EXAMPLE: % Prepare thresholds - since Z scored streams will be analyzed, input threshold as the desired SD. for eachfile = 1:length(data) data(eachfile).threshold3SD = 3; end % Find session transients by directly called in the findSessionTransients_blmean function [data] = findSessionTransients_blmean(data,'sigfiltz_normsession_trimmed','threshold3SD','fs',800,100,2000,0.5,1); findSessionTransients_blmin Sub function to detect and quantify transient events in whole session data streams. Transient baselines are defined as the minimum value within the pre-transient baseline window. This function is called by the main function findSessionTransients , which sets default parameters for transient detection and quantification. If called outside the main function, users must specify all input values manually. INPUTS: DATA: This is a structure that contains at least the data stream you want to analyze, a field with the threshold values, and a field with the sampling rate of the data stream. WHICHSTREAM: The name (string) of the field containing the stream to be analyzed for transients. WHICHTHRESHOLD: The name (string) of the field containing the prepared numeric threshold values for each stream. For example, 'threshold_3SD'. WHICHFS: The name (string) of the field containing the sampling rate of the raw data collection in Hz. PREMINSTARTMS: Number of millseconds pre-transient to use as the start of the baseline window. Reccomended value: 800 PREMINENDMS: Number of millseconds pre-transient to use as the end of the baseline window. Reccomended value: 100 POSTTRANSIENTMS: Number of millseconds post-transient to use for the post peak baseline and trimmed data output. Reccomended value: 2000 QUANTIFICATIONHEIGHT: The height at which to characterize rise time, fall time, peak width, and AUC. Must be a number between 0 and 1. Reccomended value: 0.5 OUTPUTTRANSIENTDATA: Set to 1 to output cut data streams for each transient event for further analysis or plotting. Set to 0 to skip. Reccomended value: 1 OUTPUTS: DATA: The original data structure with sessiontransients_blmin_THRESHOLDLABEL added in. For more details on individual variables, see the PASTa user guide page Transient Detection . The output contains four nested tables: INPUTS: Includes all function inputs. TRANSIENTQUANTIFICATION: Includes the quantified variables for each transient, including amplitude, rise time, fall time, width, and AUC. TRANSIENTSTREAMLOCS: Pre-transient baseline, transient peak, rise, and fall locations for each transient to match the cut transient stream data. TRANSIENTSTREAMDATA: Cut data stream from baseline window start to the end of the post-transient period for each transient event. NOTES: If called outside the main findSessionTransients function, note that users will have to input all parameters manually and no defaults will be applied. As for the main function, threshold values should be calculated before using the findSessionTransients functions. Typically thresholds are set to 2-3 SDs. If the input data stream is Z scored, this can be the actual SD threshold number. If the input data stream is not Z scored, find the corresponding value to 2-3 SDs for each subject. For transient data outputs, each transient is in a separate row. If OUTPUTTRANSIENTDATA is set to anything other than 1, the TRANSIENTSTREAMLOCS and TRANSIENTSTREAMDATA tables will be skipped and not included in the output. EXAMPLE: % Prepare thresholds - since Z scored streams will be analyzed, input threshold as the desired SD. for eachfile = 1:length(data) data(eachfile).threshold3SD = 3; end % Find session transients by directly called in the findSessionTransients_blmin function [data] = findSessionTransients_blmin(data,'sigfiltz_normsession_trimmed','threshold3SD','fs',800,100,2000,0.5,1); findSessionTransients_localmin Sub function to detect and quantify transient events in whole session data streams. Transient baselines are defined as the last local minimum value before the transient peak within the pre-transient baseline window. This function is called by the main function findSessionTransients , which sets default parameters for transient detection and quantification. If called outside the main function, users must specify all input values manually. INPUTS: DATA: This is a structure that contains at least the data stream you want to analyze, a field with the threshold values, and a field with the sampling rate of the data stream. WHICHSTREAM: The name (string) of the field containing the stream to be analyzed for transients. WHICHTHRESHOLD: The name (string) of the field containing the prepared numeric threshold values for each stream. For example, 'threshold_3SD'. WHICHFS: The name (string) of the field containing the sampling rate of the raw data collection in Hz. PREMINSTARTMS: Number of millseconds pre-transient to use as the start of the baseline window. Reccomended value: 800 PREMINENDMS: Number of millseconds pre-transient to use as the end of the baseline window. Reccomended value: 100 POSTTRANSIENTMS: Number of millseconds post-transient to use for the post peak baseline and trimmed data output. Reccomended value: 2000 QUANTIFICATIONHEIGHT: The height at which to characterize rise time, fall time, peak width, and AUC. Must be a number between 0 and 1. Reccomended value: 0.5 OUTPUTTRANSIENTDATA: Set to 1 to output cut data streams for each transient event for further analysis or plotting. Set to 0 to skip. Reccomended value: 1 OUTPUTS: DATA: The original data structure with sessiontransients_localmin_THRESHOLDLABEL added in. For more details on individual variables, see the PASTa user guide page Transient Detection . The output contains four nested tables: INPUTS: Includes all function inputs. TRANSIENTQUANTIFICATION: Includes the quantified variables for each transient, including amplitude, rise time, fall time, width, and AUC. TRANSIENTSTREAMLOCS: Pre-transient baseline (local minimum), transient peak, rise, and fall locations for each transient to match the cut transient stream data. TRANSIENTSTREAMDATA: Cut data stream from baseline window start to the end of the post-transient period for each transient event. NOTES: If called outside the main findSessionTransients function, note that users will have to input all parameters manually and no defaults will be applied. As for the main function, threshold values should be calculated before using the findSessionTransients functions. Typically thresholds are set to 2-3 SDs. If the input data stream is Z scored, this can be the actual SD threshold number. If the input data stream is not Z scored, find the corresponding value to 2-3 SDs for each subject. For transient data outputs, each transient is in a separate row. If OUTPUTTRANSIENTDATA is set to anything other than 1, the TRANSIENTSTREAMLOCS and TRANSIENTSTREAMDATA tables will be skipped and not included in the output. EXAMPLE: % Prepare thresholds - since Z scored streams will be analyzed, input threshold as the desired SD. for eachfile = 1:length(data) data(eachfile).threshold3SD = 3; end % Find session transients by directly called in the findSessionTransients_localmin function [data] = findSessionTransients_localmin(data,'sigfiltz_normsession_trimmed','threshold3SD','fs',800,100,2000,0.5,1); binSessionTransients Used to assign individual transient events to time bins within the session for analysis of changes in transients over time. By default, sessions will be divided into 5 minute bins. Number of bins per session will be calculated by the function. Users have the option to override the defaults to change the bin length and/or manually set the number of bins per session. INPUTS: DATA: This is a structure that contains at least the data stream you want to analyze, a field with the threshold values, and a field with the sampling rate of the data stream. WHICHSTREAM: The name (string) of the field containing the stream to be analyzed for transients. WHICHFS: The name (string) of the field containing the sampling rate of the raw data collection in Hz. WHICHTRANSIENTS: The name (string) of the parent field containing the table of transietns that you want to identify bins for. This is the output of the findSessionTransients function. The name usually follows the convention sessiontransients_WHICHBLTYPE_WHICHTHRESHOLD OPTIONAL INPUTS: * WHICHTRANSIENTSTABLE: The name (string) of the field within WHICHTRANSIENTS that contains the quantification of individual transient events. This input only needs to be specified if not using the format output from the FINDSESSIONTRANSIENTS functions. Default: 'transientquantification' * WHICHMAXLOCS: NThe name (string) of the field containing the transient max locations (indexes) relative to the whole session. This input only needs to be specified if not using the format output from the FINDSESSIONTRANSIENTS functions. Default: 'maxloc' * BINLENGTHMINS: Numeric; Bin length in number of minutes. Default: 5 * NBINSOVERRIDE: Numeric; Manual override to set the number of bins. If set to anything other than 0, users can override the stream-length based calculation of the number of bins per session and set their own number. Default: 0 OUTPUTS: DATA: The original data structure with sessiontransients_localmin_THRESHOLDLABEL added in. For more details on individual variables, see the PASTa user guide page Transient Detection . The output contains four nested tables: INPUTS: Includes all function inputs. TRANSIENTQUANTIFICATION: Includes the quantified variables for each transient, including amplitude, rise time, fall time, width, and AUC. TRANSIENTSTREAMLOCS: Pre-transient baseline (local minimum), transient peak, rise, and fall locations for each transient to match the cut transient stream data. TRANSIENTSTREAMDATA: Cut data stream from baseline window start to the end of the post-transient period for each transient event. NOTES: If called outside the main findSessionTransients function, note that users will have to input all parameters manually and no defaults will be applied. As for the main function, threshold values should be calculated before using the findSessionTransients functions. Typically thresholds are set to 2-3 SDs. If the input data stream is Z scored, this can be the actual SD threshold number. If the input data stream is not Z scored, find the corresponding value to 2-3 SDs for each subject. For transient data outputs, each transient is in a separate row. If OUTPUTTRANSIENTDATA is set to anything other than 1, the TRANSIENTSTREAMLOCS and TRANSIENTSTREAMDATA tables will be skipped and not included in the output. EXAMPLE: % Prepare thresholds - since Z scored streams will be analyzed, input threshold as the desired SD. for eachfile = 1:length(data) data(eachfile).threshold3SD = 3; end % Find session transients by directly called in the findSessionTransients_localmin function [data] = findSessionTransients_localmin(data,'sigfiltz_normsession_trimmed','threshold3SD','fs',800,100,2000,0.5,1); exportSessionTransients Used to create a table of all transient events across all sessions included in the file key and data structure, and exports the table of transient quantification to a csv file. This function depends on the output from findSessionTransients . The creation of a csv file is helpful for users who prefer to run statistical analyses or make plots in other programs than MATLAB, such as R Studio. INPUTS: DATA: This is a structure that contains at least the output from findSessionTransients . WHICHTRANSIENTS: The name (string) of the parent field containing the table of transietns that you want to identify bins for. This is the output of the findSessionTransients function. The name usually follows the convention sessiontransients_WHICHBLTYPE_WHICHTHRESHOLD EXPORTFILEPATH: A string with the path to the folder location where the created table should be saved to. NOTE: The path must end in a forward slash. ADDVARIABLES: A cell array containing any additional variables from the data structure to be added to the transients table. Variables will be added to every row of the output structure. Cell array inputs must be the names of fields in the data structure. At a minimum, this should contain the subject ID. If multiple sessions per subject are included in the data structure, make sure a session ID variable is also included. For example: {'Subject', 'SessionID', 'Treatment'} OPTIONAL INPUTS: * WHICHTRANSIENTSTABLE: The name (string) of the field within WHICHTRANSIENTS that contains the quantification of individual transient events. This input only needs to be specified if not using the format output from the FINDSESSIONTRANSIENTS functions. Default: 'transientquantification' * FILENAME: A string with a custom name for the output csv file. If not specified, the file name will be generated as 'WHICHTRANSIENTS_AllSessionExport_DAY-MONTH-YEAR.csv' OUTPUTS: This function outputs a csv file with all transients for all sessions in the data structure. The file will be output at the specified file path. If the function is called into an object, the table ALLTRANSIENTS will also be saved to an object in the MATLAB workspace. NOTES: The file path must include the full path for the folder including the computer address, and must end in a forward slash. If the file path is not specified properly, the function won't be able to automatically save the csv file. Make sure to add all relevant experimental variables to the ADDVARIABLES list. This includes at a minimum the Subject ID and a session ID, but it's wise to include other key variables to make future analyses easier. Alternatively, you can keep only the Subject ID and a session ID and match the data to the subject and file keys later, which would include all subject and experimental variables. EXAMPLE: % Export transients with added fields for subject and treatment= addvariables = {'Subject','TreatNum','InjType'}; % Prepare variables to append to each transient % To just output the csv file: exportSessionTransients(data,'sessiontransients_blmean_threshold3SD',analysispath,addvariables); % To output the csv file and add the created table to a MATLAB data structure: alltransients = exportSessionTransients(data,'sessiontransients_blmean_threshold3SD',analysispath,addvariables); Visualization and Plotting Functions plotTraces Main function to plot whole session fiber photometry traces. This function will plot the streams sig, baq, baq_scaled, sigsub, and sigfilt for a single session. Use this function in a loop to plot streams for all sessions in the data structure. This plot function plots the data streams with time in minutes on the x axis. To modify the plot or add additional features like session relevant time stamps, use the plot in a loop. Modified plots must be saved in the external loop. If modifications are not neccesaary, then optional inputs can be specified to directly output and save the plot to a filepath location. INPUTS: DATA: This is a structure that contains at least the data stream you want to analyze, a field with the threshold values, and a field with the sampling rate of the data stream. WHICHFILE: The file number to be plotted. MAINTITLE: The main title (string) to be displayed for the overall plot above the individual tiles. For example, '427 - Treatment: Morphine' OPTIONAL INPUTS: SAVEOUTPUT: Set to 1 to automatically save trace plots as png to the plot file path. Default: 0 PLOTFILEPATH: Required if SAVEOUTPUT is set to 1. The specific path to save the plot to. Note that this must be the entire path from computer address to folder ending in the filename for the specific plot. For example: 'C:\\Users\\rmdon\\Box\\Injection Transients\\Figures\\SessionTraces_427_Morphine.png' OUTPUTS: ALLTRACES: A plot object containing subplots for each input stream. EXAMPLE: Single Session %% Plot the first session and automatically save the output maintitle = append(num2str(data(1).Subject),' - Treatment: ',data(1).InjType); % Create title string for current plot plotfilepath = 'C:\\Users\\rmdon\\Box\\Injection Transients\\Figures\\SessionTraces_427_Morphine.png'; % Create plot file path for the current plot plotTraces(data,1,maintitle,'saveoutput',1,'plotfilepath',plotfilepath); EXAMPLE: All Sessions %% Plot whole session streams for each file for eachfile = 1:length(data) maintitle = append(num2str(data(eachfile).Subject),' - Treatment: ',data(eachfile).InjType); % Create title string for current plot alltraces = plotTraces(data,eachfile,maintitle); for eachtile = 1:5 nexttile(eachtile) xline(data(eachfile).injt(1),'--','Injection','Color','#C40300','FontSize',8) xline(data(eachfile).injt(2),'--','Color','#C40300','FontSize',8) end set(gcf, 'Units', 'inches', 'Position', [0, 0, 8, 9]); plotfilepath = append(figurepath,'SessionTraces_',num2str(data(eachfile).Subject),'_',data(eachfile).InjType,'.png'); exportgraphics(gcf,plotfilepath,'Resolution',300) end plotFFTs Main function to plot whole session fiber photometry FFT frequency magnitude plots. This function will plot the streams sig, baq, baq_scaled, sigsub, and sigfilt for a single session. Use this function in a loop to plot streams for all sessions in the data structure. By default, only frequencies up to 20 hz will be plotted but users can specify an optional input to adjust the cutoff lower or higher, or set to the actual max for the stream FFT. To modify the plot or add additional features, use the plot in a loop. Modified plots must be saved in the external loop. If modifications are not neccesaary, then optional inputs can be specified to directly output and save the plot to a filepath location. INPUTS: DATA: This is a structure that contains at least the data stream you want to analyze, a field with the threshold values, and a field with the sampling rate of the data stream. WHICHFILE: The file number to be plotted. MAINTITLE: The main title (string) to be displayed for the overall plot above the individual tiles. For example, '427 - Treatment: Morphine' WHICHFS: The name (string) of the field that contains the sampling rate of the data streams. OPTIONAL INPUTS: XMAX: The desired frequency cutoff for the x axis (hz). Frequencies above this value will be excluded from the plots. To plot all frequencies, set to actual'. Default: 20 SAVEOUTPUT: Set to 1 to automatically save trace plots as png to the plot file path. Default: 0 PLOTFILEPATH: Required if SAVEOUTPUT is set to 1. The specific path to save the plot to. Note that this must be the entire path from computer address to folder ending in the filename for the specific plot. For example: 'C:\\Users\\rmdon\\Box\\Injection Transients\\Figures\\SessionTraces_427_Morphine.png' OUTPUTS: ALLFFTS: A plot object containing subplots for each input stream. EXAMPLE: Single Session %% Plot the first session and automatically save the output maintitle = append(num2str(data(1).Subject),' - Treatment: ',data(1).InjType); % Create title string for current plot plotfilepath = 'C:\\Users\\rmdon\\Box\\Injection Transients\\Figures\\SessionTraces_427_Morphine.png'; % Create plot file path for the current plot plotTraces(data,1,maintitle,'fs','saveoutput',1,'plotfilepath',plotfilepath); EXAMPLE: All Sessions %% Plot stream FFTs for each file for eachfile = 1:length(data) maintitle = append(num2str(data(eachfile).Subject),' - Treatment: ',data(eachfile).InjType); % Create title string for current plot allffts = plotFFTs(data,eachfile,maintitle); set(gcf, 'Units', 'inches', 'Position', [0, 0, 8, 9]); plotfilepath = append(figurepath,'SessionFFTs_',num2str(data(eachfile).Subject),'_',data(eachfile).InjType,'.png'); exportgraphics(gcf,plotfilepath,'Resolution',300) end","title":"Function Documentation"},{"location":"functiondocumentation/#function-documentation-overview","text":"This page contains additional documentation for each function within PASTa, as well as examples of inputs.","title":"Function Documentation Overview"},{"location":"functiondocumentation/#data-preparation-functions","text":"This set of functions is used to prepare raw photometry data, match it with experimental metadata, and load data into a structure in MATLAB. Functions are provided to handle data collected via TDT equipment and software Synapse, or a generic file structure with data streams saved to CSV files.","title":"Data Preparation Functions"},{"location":"functiondocumentation/#loadkeys","text":"Combines subject key and file key into a data structure, and appends the provided computeruserpath to the paths in the file key. INPUTS: COMPUTERUSERPATH: A variable containing the unique portion of the file explorer path for the users specific computer. For example, 'C:\\Users\\rmdon\\'. Make sure the computeruserpath ends in a forward slash. SUBJECTKEYNAME: A variable containing a string with the name of the subject key csv file for the experiment (see \"3. Data Analysis Pipeline\" for more details). To omit a subject key and only load in the file key, set subjectkeyname = \"\". FILEKEYNAME: A variable containing a string with the name of the file key csv file for the experiment (see \"3. Data Analysis Pipeline\" for more details). OUTPUTS: EXPERIMENTKEY: A data structure called \"experimentkey\" that includes the joined file key and subject key with the computer user path appended to raw and extracted folder paths. EXAMPLE: computeruserpath = 'C:\\Users\\MYNAME\\'; % Computer specific portion of file navigation paths subjectkeyname = 'Subject Key.csv'; % Name of csv file containing subject information; set to '' if not using a subject key filekeyname = 'File Key.csv'; % Name of csv file containing session information, raw data folder names, and paths [experimentkey] = loadKeys(computeruserpath, subjectkeyname, filekeyname); % Load keys into a data structure called experimentkey NOTES: FILEKEY must contain at a minimum the fields Subject , RawFolderPath , and ExtractedFolderPath . SUBJECTKEY must contain at a minimum the field Subject Folder paths must end with a slash. The subject and file keys are joined based on Subject ID. Subject key must contain every subjects in the file key. If there is a mismatch, you will receive an error message that the right table does not contain all the key variables that are in the left table. The error message will display the unique subject IDs present in each key so you can determine where the mismatch occurred. Fields in subject and file key must be named uniquely. The only field that should be named the same in both keys is Subject.","title":"loadKeys"},{"location":"functiondocumentation/#extracttdtdata","text":"This function is used to extract TDT data from saved blocks recorded via the software Synapse . For each block, extractTDTdata calls the function \"TDTbin2mat\" (TDT, 2019) and inputs the RawFolderPath to extract fiber photometry data recorded with Synapse. Extracted blocks are parsed it into a single data structure containing all fields, streams, and epocs. Extracted signal streams are trimmed to remove the first 5 seconds by default (trimming can be adjusted if desired). The function will identify the signal channel by matching the names in the input SIGSTREAMNAMES and the control channel by matching the names in the input BAQSTREAMNAMES. The name inputs can include a list of stream names if channel naming conventions vary by rig. Each block is saved as a separate data structure in a '.mat' file at the location specified by the inputs in extractedfolderpaths. INPUTS: RAWFOLDERPATHS: a string array containing the paths to the folder location of the raw data blocks to be extracted. The string array should contain one column with each full path in a separate row. EXTRACTEDFOLDERPATHS: a string array containing the paths to the folder location in which to save the extracted MatLab structs for each block to be extracted. The string array should contain one column with each full path in a separate row. SIGSTREAMNAMES: A cell array containing strings with the names of the streams to be treated as signal. Note that only one stream per file can be treated as signal. If different files have different stream names, include all stream names in the cell array. BAQSTREAMNAMES: A cell array containing strings with the names of the streams to be treated as background. Note that only one stream per file can be treated as background. If different files have different stream names, include all stream names in the cell array. OPTIONAL INPUTS: TRIM: the number of seconds to remove on either end of the data streams. If not specified, defaults to 5 seconds. SKIPEXISTING: A binary variable containing a 0 if pre-existing extracted blocks should be re-extracted or a 1 if pre-existing extracted blocks should be skipped. This allows the user to toggle whether or not to extract every block, or only blocks that have not previously been extracted. If not specified, defaults to 1 (skip previously extracted blocks). OUTPUTS: Saved .mat data structures for each block in the location specified by extractedfolderpaths. EXAMPLE - DEFAULT: sigstreamnames = {'x65A', '465A'}; % All names of signal streams across files baqstreamnames = {'x05A', '405A'}; % All names of background streams across files rawfolderpaths = string({experimentkey.RawFolderPath})'; % Create string array of raw folder paths extractedfolderpaths = string({experimentkey.ExtractedFolderPath})'; % Create string array of extracted folder paths extractTDTdata(rawfolderpaths,extractedfolderpaths,sigstreamnames,baqstreamnames); % extract data EXAMPLE - MANUALLY SPECIFIED TRIM AND SKIPEXISTING: trim = 3; skipexisting = 0; sigstreamnames = {'x65A', '465A'}; % All names of signal streams across files baqstreamnames = {'x05A', '405A'}; % All names of background streams across files rawfolderpaths = string({experimentkey.RawFolderPath})'; % Create string array of raw folder paths' extractedfolderpaths = string({experimentkey.ExtractedFolderPath})'; % Create string array of extracted folder paths' extractTDTdata(rawfolderpaths,extractedfolderpaths,sigstreamnames,baqstreamnames,'trim',trim,'skipexisting',skipexisting); % extract data","title":"extractTDTdata"},{"location":"functiondocumentation/#loadtdtdata","text":"For use with previously extracted data collect with TDT equipment and software Synapse. loadTDTData loads previously extracted .mat data blocks into a data structure for further analysis. Each block is one row. The input experiment key must include at a minimum the extracted folder path location of the block. Any additional information about the subject and session in the experiment key will be matched to the extracted data. INPUTS: EXPERIMENTKEY: A prepared data structure with at minimum the ExtractedFolderPath containing the full path to the individual session data structures to be loaded. The EXPERIMENTKEY can be prepared with the LOADKEYS function. OUTPUTS: DATA: the input data structure with each individual extracted block added by row. EXAMPLE: [rawdata] = loadKeydata(experimentkey); % Load data based on the experiment key into the structure 'rawdata'","title":"loadTDTdata"},{"location":"functiondocumentation/#loadcsvdata","text":"For use with data collected and stored to a general file structure. coming soon","title":"loadCSVdata"},{"location":"functiondocumentation/#cropfpdata","text":"Used to crop data streams to remove portions that are not to be included in analysis (such as the the first two minutes of the session, or the first samples before a hardware control program is initiated). Crops all specified data streams from the index in cropstart to the index in cropend, and adjusts epocs by the amount cropped by cropstart. Users must pre-prepare the crop start and end indexes to specify as inputs for the function. INPUTS: DATA: A data frame containing at least the specified input fields. CROPSTART: The location to start cropping at. CROPEND: The location to end cropping at. WHICHSTREAMS: A cell array containing the names of all the streams to be cropped. OPTIONAL INPUTS: WHICHEPOCS: A cell array containing the names of all the epocs to be adjusted due to cropping - subtract the (start loc - 1) from the epoc. OUTPUTS: DATA: The data structure with the specified data stream containing the cropped data. EXAMPLE: cropstart = 'sessionstart'; % name of field with session start index cropend = 'sessionend'; % name of field with session end index whichstreams = {'sig', 'baq','time'}; % which streams to crop whichepocs = {'injt','sess'}; % which epocs to adjust to maintain relative position [data] = cropFPdata(rawdata,cropstart,cropend, whichstreams,whichepocs); % Output cropped data into new structure called data","title":"cropFPdata"},{"location":"functiondocumentation/#signal-processing-functions","text":"","title":"Signal Processing Functions"},{"location":"functiondocumentation/#subtractfpdata","text":"Used to subtract the background photometry stream (eg, 405nm) from the signal stream (eg, 465nm), convert the subtracted signal to delta F/f, and apply a filter to denoise the output. Users must input the data structure with the raw data, the names of the fields containing the signal and background streams, and the sampling rate of the collected data. INPUTS: DATA: A data frame containing at least the specified input fields. SIGFIELD: The name (string) of the field containing the signal stream. BAQFIELD: The name (string) of the field containing the background stream. WHICHFS: The name (string) of the field containing the sampling rate of the raw data collection in Hz. OPTIONAL INPUTS: BAQSCALINGTYPE: A string to specify the type of background scaling to apply. Options are 'frequency', 'sigmean', 'OLS', 'detrendOLS', 'smoothedOLS', or 'IRLS'. Default: 'frequency'. 'frequency': Scales the background to the signal channel based on ratio of specified frequency bands in the FFT (frequency domain) of the channels. 'sigmean': Scales the background to the signal channel based on the ratio of the mean of the signal to the mean of the background (time domain). 'OLS': Uses ordinary least-squares regression to generate scaled background. 'detrendOLS': Removes the linear trend from signal and background streams prior to using ordinary least-squares regression to generate scaled background. 'smoothedOLS': Applies lowess smoothing to the signal and background streams prior to using ordinary least-squares regression to generate scaled background. 'IRLS': Uses iteratively reweighted least squares regression to generate scaled background. BAQSCALINGFREQ: Only used with 'frequency' scaling. Numeric frequency (Hz) threshold for scaling the background to signal channel. Frequencies above this value will be included in the scaling factor determination. Default: 10 Hz. BAQSCALINGPERC: Only used with 'frequency' and 'sigmean' scaling. Adjusts the background scaling factor to be a percent of the derived scaling factor value. Default: 1 (100%). SUBTRACTIONOUTPUT: Output type for the subtracted data. Default: 'dff' 'dff': Outputs subtracted signal as delta F/F. 'df': Outputs subtracted signal as delta F. FILTERTYPE: A string to specify the type of filter to apply after subtraction. Default: 'bandpass'. 'nofilter': No filter will be applied. 'bandpass': A bandpass filter will be applied. 'highpass': Only the high pass filter will be applied. 'lowpass': Only the low pass filter will be applied. PADDING: Defaults to 1, which applies padding. Padding takes the first 10% of the stream, flips it, and appends it to the data before filtering. Appended data is trimmed after filtration. Set to 0 to turn off padding of data streams. Default: 1. PADDINGPERC: Percent of data length to use to determine the number of samples to be appended to the beginning and end of data in padding. Set to minimum 10%. Default: 0.1 (10%). FILTERORDER: The order to be used for the chosen butterworth filter. Default: 3. HIGHPASSCUTOFF: The cutoff frequency (hz) to be used for the high pass butterworth filter. Default: 2.2860. LOWPASSCUTOFF: The cutoff to be used for the low pass butterworth filter. Default: 0.0051. NOTE: 'bandpass' applies both the high and low cutoffs to design the filter. SUPRESSDISP: If set to anything other than 0, this will suppress the command window displays. Default: 0. OUTPUTS: DATA: The original data structure with added fields with the scaled background ('baq_scaled'), subtracted signal ('sigsub'), and subtracted and filtered signal ('sigfilt'). All inputs and defaults will be added to the data structure under the field 'inputs'. NOTE: If using BAQSCALINGMETHOD 'detrendOLS' , additional fields containing the detrended signal and background ('sig_detrend' and 'baq_detrend') will be added to the data frame. If using BAQSCALINGMETHOD 'smoothedOLS' , additional fields containing the smoothed signal and background ('sig_smoothed' and 'baq_smoothed') will be added to the data frame. EXAMPLE - DEFAULT: sigfield = 'sig'; baqfield = 'baq'; fs = 1017; data = subtractFPdata(data,sigfield,baqfield,fs); EXAMPLE - Frequency Scaling with 20Hz Threshold and Highpass Filter Only: sigfield = 'sig'; baqfield = 'baq'; fs = 1017; data = subtractFPdata(data,sigfield,baqfield,fs,'baqscalingfreq',20,'filtertype,'highpass');","title":"subtractFPdata"},{"location":"functiondocumentation/#normsession","text":"Used to normalize the subtracted and filtered signal stream to Z score based on the whole session mean and standard deviation. INPUTS: DATA: A data frame containing at least the stream specified to be normalized. WHICHSTREAM: A string with the name of the field containing the stream to be normalized. OUTPUTS: DATA: The data structure with the field 'data.WHICHSTREAMz_normsession' containing the whole session normalized signal added. EXAMPLE: [data] = normSession(data,'sigfilt'); % Outputs whole session z score","title":"normSession"},{"location":"functiondocumentation/#normbaseline","text":"Used to normalize the subtracted and filtered signal stream to Z score based on the a session baseline mean and standard deviation. INPUTS: DATA: A data frame containing at least the stream specified to be normalized. WHICHSTREAM: A string with the name of the field containing the stream to be normalized. WHICHBLSTART: A string with the name of the field containing the index of the start of the baseline period. WHICHBLEND: A string with the name of the field containing the index of the end of the baseline period. OUTPUTS: DATA: The data structure with the field 'data.WHICHSTREAMz_normbaseline' containing the full stream normalized to baseline added. EXAMPLE: % Prepare baseline start and end indices for eachfile = 1:length(data) % prepare indexes for baseline period start and end data(eachfile).BLstart = 1; data(eachfile).BLend = data(eachfile).injt(1); end % Normalize filtered signal to session baseline mean and SD [data] = normBaseline(data,'sigfilt','BLstart','BLend');","title":"normBaseline"},{"location":"functiondocumentation/#preparestreamfft","text":"Helper function to take the FFT of a data stream and output the magnitudes and corresponding frequencies for analysis, plotting, and diagnostics. This function is called by the plot function plotFFTs but can also be used to prepare FFTs for each stream of data for all sessions with use in a for loop. INPUTS: STREAMDATA: An array containing the values from a single collected data stream. FS: The sampling rate of the data stream. OUTPUTS: STREAMFFT: An array containing the prepared FFT magnitudes of the input stream. STREAMF: An array containing the corresponding frequencies to the prepared FFT magnitudes in STREAMFFT. EXAMPLE OF SINGLE SESSION SIGNAL: [streamFFT,streamF] = preparestreamFFT(data(1).sig,data(eachfile).fs); EXAMPLE OF ALL SESSIONS AND STREAMS: %% Prepare FFTs of all streams streams = {'sig', 'baq', 'baq_scaled','sigsub', 'sigfilt'}; % Frequency scaled background for eachfile = 1:length(data) for eachstream = 1:length(streams) streamname = char(streams(eachstream)); [streamFFT,streamF] = preparestreamFFT(data(eachfile).(streamname),data(eachfile).fs); data(eachfile).(append(streamname,'FFT')) = streamFFT; data(eachfile).(append(streamname,'F')) = streamF; end end","title":"preparestreamFFT"},{"location":"functiondocumentation/#transient-detection-and-quantification-functions","text":"","title":"Transient Detection and Quantification Functions"},{"location":"functiondocumentation/#findsessiontransients","text":"Main function to detect and quantify transient events in whole session data streams. Use of this main function will set default values for parameters not specific as optional inputs. Users must input the raw data structure containing the data stream, a field with threshold values for transient inclusion, and the sampling rate of the stream. Optional inputs can be specified to modify transient detection parameters, but defaults will be applied if not specified. INPUTS: DATA: This is a structure that contains at least the data stream you want to analyze, a field with the threshold values, and a field with the sampling rate of the data stream. WHICHBLTYPE: A string with the type of pre-transient baseline to use for amplitude inclusion and quantification. 'blmean': Pre-transient baselines are set to the mean of the pre-transient window. 'blmin': Pre-transient baselines are set to the minimum value within the pre-transient window. 'localmin': Pre-transient baselines are set to the local minimum directly preceding the transient within the baseline window. WHICHSTREAM: The name (string) of the field containing the stream to be analyzed for transients. WHICHTHRESHOLD: The name (string) of the field containing the prepared numeric threshold values for each stream. For example, 'threshold_3SD'. WHICHFS: The name (string) of the field containing the sampling rate of the raw data collection in Hz. OPTIONAL INPUTS: PREMINSTARTMS: Number of millseconds pre-transient to use as the start of the baseline window. Default: 800 PREMINENDMS: Number of millseconds pre-transient to use as the end of the baseline window. Default: 100 POSTTRANSIENTMS: Number of millseconds post-transient to use for the post peak baseline and trimmed data output. Default: 2000 QUANTIFICATIONHEIGHT: The height at which to characterize rise time, fall time, peak width, and AUC. Must be a number between 0 and 1. Default: 0.5 OUTPUTTRANSIENTDATA: Set to 1 to output cut data streams for each transient event for further analysis or plotting. Set to 0 to skip. Default: 1 OUTPUTS: DATA: The original data structure with sessiontransients_WHICHBLTYPE_THRESHOLDLABEL added in. For more details on individual variables, see the PASTa user guide page Transient Detection . The output contains four nested tables: INPUTS: Includes all required and optional inputs. If optional inputs are not specified, defaults will be applied. TRANSIENTQUANTIFICATION: Includes the quantified variables for each transient, including amplitude, rise time, fall time, width, and AUC. TRANSIENTSTREAMLOCS: Pre-transient baseline, transient peak, rise, and fall locations for each transient to match the cut transient stream data. _TRANSIENTSTREAMDATA: Cut data stream from baseline start to the end of the post-transient period for each transient event. NOTES: Threshold values should be calculated before using the findSessionTransients functions. Typically thresholds are set to 2-3 SDs. If the input data stream is Z scored, this can be the actual SD threshold number. If the input data stream is not Z scored, find the corresponding value to 2-3 SDs for each subject. For transient data outputs, each transient is in a separate row. If OUTPUTTRANSIENTDATA is set to anything other than 1, the TRANSIENTSTREAMLOCS and TRANSIENTSTREAMDATA tables will be skipped and not included in the output. EXAMPLE: % Prepare thresholds - since Z scored streams will be analyzed, input threshold as the desired SD. for eachfile = 1:length(data) data(eachfile).threshold3SD = 3; end % Find session transients based on pre-peak baseline window minimum [data] = findSessionTransients(data,'blmin','sigfiltz_normsession_trimmed','threshold3SD','fs'); % Find session transients based on pre-peak baseline window mean [data] = findSessionTransients(data,'blmean','sigfiltz_normsession_trimmed','threshold3SD','fs','preminstartms',600); % Find session transients based on pre-peak local minimum (last minumum before the peak in the baseline window) [data] = findSessionTransients(data,'localmin','sigfiltz_normsession_trimmed','threshold3SD','fs','quantificationheight',0.25);","title":"findSessionTransients"},{"location":"functiondocumentation/#findsessiontransients_blmean","text":"Sub function to detect and quantify transient events in whole session data streams. Transient baselines are defined as the mean of the pre-transient baseline window. This function is called by the main function findSessionTransients , which sets default parameters for transient detection and quantification. If called outside the main function, users must specify all input values manually. INPUTS: DATA: This is a structure that contains at least the data stream you want to analyze, a field with the threshold values, and a field with the sampling rate of the data stream. WHICHSTREAM: The name (string) of the field containing the stream to be analyzed for transients. WHICHTHRESHOLD: The name (string) of the field containing the prepared numeric threshold values for each stream. For example, 'threshold_3SD'. WHICHFS: The name (string) of the field containing the sampling rate of the raw data collection in Hz. PREMINSTARTMS: Number of millseconds pre-transient to use as the start of the baseline window. Reccomended value: 800 PREMINENDMS: Number of millseconds pre-transient to use as the end of the baseline window. Reccomended value: 100 POSTTRANSIENTMS: Number of millseconds post-transient to use for the post peak baseline and trimmed data output. Reccomended value: 2000 QUANTIFICATIONHEIGHT: The height at which to characterize rise time, fall time, peak width, and AUC. Must be a number between 0 and 1. Reccomended value: 0.5 OUTPUTTRANSIENTDATA: Set to 1 to output cut data streams for each transient event for further analysis or plotting. Set to 0 to skip. Reccomended value: 1 OUTPUTS: DATA: The original data structure with sessiontransients_blmean_THRESHOLDLABEL added in. For more details on individual variables, see the PASTa user guide page Transient Detection . The output contains four nested tables: INPUTS: Includes all function inputs. TRANSIENTQUANTIFICATION: Includes the quantified variables for each transient, including amplitude, rise time, fall time, width, and AUC. TRANSIENTSTREAMLOCS: Pre-transient baseline start, pre-transient baseline end, transient peak, rise, and fall locations for each transient to match the cut transient stream data. _TRANSIENTSTREAMDATA: Cut data stream from baseline window start to the end of the post-transient period for each transient event. NOTES: If called outside the main findSessionTransients function, note that users will have to input all parameters manually and no defaults will be applied. As for the main function, threshold values should be calculated before using the findSessionTransients functions. Typically thresholds are set to 2-3 SDs. If the input data stream is Z scored, this can be the actual SD threshold number. If the input data stream is not Z scored, find the corresponding value to 2-3 SDs for each subject. For transient data outputs, each transient is in a separate row. If OUTPUTTRANSIENTDATA is set to anything other than 1, the TRANSIENTSTREAMLOCS and TRANSIENTSTREAMDATA tables will be skipped and not included in the output. EXAMPLE: % Prepare thresholds - since Z scored streams will be analyzed, input threshold as the desired SD. for eachfile = 1:length(data) data(eachfile).threshold3SD = 3; end % Find session transients by directly called in the findSessionTransients_blmean function [data] = findSessionTransients_blmean(data,'sigfiltz_normsession_trimmed','threshold3SD','fs',800,100,2000,0.5,1);","title":"findSessionTransients_blmean"},{"location":"functiondocumentation/#findsessiontransients_blmin","text":"Sub function to detect and quantify transient events in whole session data streams. Transient baselines are defined as the minimum value within the pre-transient baseline window. This function is called by the main function findSessionTransients , which sets default parameters for transient detection and quantification. If called outside the main function, users must specify all input values manually. INPUTS: DATA: This is a structure that contains at least the data stream you want to analyze, a field with the threshold values, and a field with the sampling rate of the data stream. WHICHSTREAM: The name (string) of the field containing the stream to be analyzed for transients. WHICHTHRESHOLD: The name (string) of the field containing the prepared numeric threshold values for each stream. For example, 'threshold_3SD'. WHICHFS: The name (string) of the field containing the sampling rate of the raw data collection in Hz. PREMINSTARTMS: Number of millseconds pre-transient to use as the start of the baseline window. Reccomended value: 800 PREMINENDMS: Number of millseconds pre-transient to use as the end of the baseline window. Reccomended value: 100 POSTTRANSIENTMS: Number of millseconds post-transient to use for the post peak baseline and trimmed data output. Reccomended value: 2000 QUANTIFICATIONHEIGHT: The height at which to characterize rise time, fall time, peak width, and AUC. Must be a number between 0 and 1. Reccomended value: 0.5 OUTPUTTRANSIENTDATA: Set to 1 to output cut data streams for each transient event for further analysis or plotting. Set to 0 to skip. Reccomended value: 1 OUTPUTS: DATA: The original data structure with sessiontransients_blmin_THRESHOLDLABEL added in. For more details on individual variables, see the PASTa user guide page Transient Detection . The output contains four nested tables: INPUTS: Includes all function inputs. TRANSIENTQUANTIFICATION: Includes the quantified variables for each transient, including amplitude, rise time, fall time, width, and AUC. TRANSIENTSTREAMLOCS: Pre-transient baseline, transient peak, rise, and fall locations for each transient to match the cut transient stream data. TRANSIENTSTREAMDATA: Cut data stream from baseline window start to the end of the post-transient period for each transient event. NOTES: If called outside the main findSessionTransients function, note that users will have to input all parameters manually and no defaults will be applied. As for the main function, threshold values should be calculated before using the findSessionTransients functions. Typically thresholds are set to 2-3 SDs. If the input data stream is Z scored, this can be the actual SD threshold number. If the input data stream is not Z scored, find the corresponding value to 2-3 SDs for each subject. For transient data outputs, each transient is in a separate row. If OUTPUTTRANSIENTDATA is set to anything other than 1, the TRANSIENTSTREAMLOCS and TRANSIENTSTREAMDATA tables will be skipped and not included in the output. EXAMPLE: % Prepare thresholds - since Z scored streams will be analyzed, input threshold as the desired SD. for eachfile = 1:length(data) data(eachfile).threshold3SD = 3; end % Find session transients by directly called in the findSessionTransients_blmin function [data] = findSessionTransients_blmin(data,'sigfiltz_normsession_trimmed','threshold3SD','fs',800,100,2000,0.5,1);","title":"findSessionTransients_blmin"},{"location":"functiondocumentation/#findsessiontransients_localmin","text":"Sub function to detect and quantify transient events in whole session data streams. Transient baselines are defined as the last local minimum value before the transient peak within the pre-transient baseline window. This function is called by the main function findSessionTransients , which sets default parameters for transient detection and quantification. If called outside the main function, users must specify all input values manually. INPUTS: DATA: This is a structure that contains at least the data stream you want to analyze, a field with the threshold values, and a field with the sampling rate of the data stream. WHICHSTREAM: The name (string) of the field containing the stream to be analyzed for transients. WHICHTHRESHOLD: The name (string) of the field containing the prepared numeric threshold values for each stream. For example, 'threshold_3SD'. WHICHFS: The name (string) of the field containing the sampling rate of the raw data collection in Hz. PREMINSTARTMS: Number of millseconds pre-transient to use as the start of the baseline window. Reccomended value: 800 PREMINENDMS: Number of millseconds pre-transient to use as the end of the baseline window. Reccomended value: 100 POSTTRANSIENTMS: Number of millseconds post-transient to use for the post peak baseline and trimmed data output. Reccomended value: 2000 QUANTIFICATIONHEIGHT: The height at which to characterize rise time, fall time, peak width, and AUC. Must be a number between 0 and 1. Reccomended value: 0.5 OUTPUTTRANSIENTDATA: Set to 1 to output cut data streams for each transient event for further analysis or plotting. Set to 0 to skip. Reccomended value: 1 OUTPUTS: DATA: The original data structure with sessiontransients_localmin_THRESHOLDLABEL added in. For more details on individual variables, see the PASTa user guide page Transient Detection . The output contains four nested tables: INPUTS: Includes all function inputs. TRANSIENTQUANTIFICATION: Includes the quantified variables for each transient, including amplitude, rise time, fall time, width, and AUC. TRANSIENTSTREAMLOCS: Pre-transient baseline (local minimum), transient peak, rise, and fall locations for each transient to match the cut transient stream data. TRANSIENTSTREAMDATA: Cut data stream from baseline window start to the end of the post-transient period for each transient event. NOTES: If called outside the main findSessionTransients function, note that users will have to input all parameters manually and no defaults will be applied. As for the main function, threshold values should be calculated before using the findSessionTransients functions. Typically thresholds are set to 2-3 SDs. If the input data stream is Z scored, this can be the actual SD threshold number. If the input data stream is not Z scored, find the corresponding value to 2-3 SDs for each subject. For transient data outputs, each transient is in a separate row. If OUTPUTTRANSIENTDATA is set to anything other than 1, the TRANSIENTSTREAMLOCS and TRANSIENTSTREAMDATA tables will be skipped and not included in the output. EXAMPLE: % Prepare thresholds - since Z scored streams will be analyzed, input threshold as the desired SD. for eachfile = 1:length(data) data(eachfile).threshold3SD = 3; end % Find session transients by directly called in the findSessionTransients_localmin function [data] = findSessionTransients_localmin(data,'sigfiltz_normsession_trimmed','threshold3SD','fs',800,100,2000,0.5,1);","title":"findSessionTransients_localmin"},{"location":"functiondocumentation/#binsessiontransients","text":"Used to assign individual transient events to time bins within the session for analysis of changes in transients over time. By default, sessions will be divided into 5 minute bins. Number of bins per session will be calculated by the function. Users have the option to override the defaults to change the bin length and/or manually set the number of bins per session. INPUTS: DATA: This is a structure that contains at least the data stream you want to analyze, a field with the threshold values, and a field with the sampling rate of the data stream. WHICHSTREAM: The name (string) of the field containing the stream to be analyzed for transients. WHICHFS: The name (string) of the field containing the sampling rate of the raw data collection in Hz. WHICHTRANSIENTS: The name (string) of the parent field containing the table of transietns that you want to identify bins for. This is the output of the findSessionTransients function. The name usually follows the convention sessiontransients_WHICHBLTYPE_WHICHTHRESHOLD OPTIONAL INPUTS: * WHICHTRANSIENTSTABLE: The name (string) of the field within WHICHTRANSIENTS that contains the quantification of individual transient events. This input only needs to be specified if not using the format output from the FINDSESSIONTRANSIENTS functions. Default: 'transientquantification' * WHICHMAXLOCS: NThe name (string) of the field containing the transient max locations (indexes) relative to the whole session. This input only needs to be specified if not using the format output from the FINDSESSIONTRANSIENTS functions. Default: 'maxloc' * BINLENGTHMINS: Numeric; Bin length in number of minutes. Default: 5 * NBINSOVERRIDE: Numeric; Manual override to set the number of bins. If set to anything other than 0, users can override the stream-length based calculation of the number of bins per session and set their own number. Default: 0 OUTPUTS: DATA: The original data structure with sessiontransients_localmin_THRESHOLDLABEL added in. For more details on individual variables, see the PASTa user guide page Transient Detection . The output contains four nested tables: INPUTS: Includes all function inputs. TRANSIENTQUANTIFICATION: Includes the quantified variables for each transient, including amplitude, rise time, fall time, width, and AUC. TRANSIENTSTREAMLOCS: Pre-transient baseline (local minimum), transient peak, rise, and fall locations for each transient to match the cut transient stream data. TRANSIENTSTREAMDATA: Cut data stream from baseline window start to the end of the post-transient period for each transient event. NOTES: If called outside the main findSessionTransients function, note that users will have to input all parameters manually and no defaults will be applied. As for the main function, threshold values should be calculated before using the findSessionTransients functions. Typically thresholds are set to 2-3 SDs. If the input data stream is Z scored, this can be the actual SD threshold number. If the input data stream is not Z scored, find the corresponding value to 2-3 SDs for each subject. For transient data outputs, each transient is in a separate row. If OUTPUTTRANSIENTDATA is set to anything other than 1, the TRANSIENTSTREAMLOCS and TRANSIENTSTREAMDATA tables will be skipped and not included in the output. EXAMPLE: % Prepare thresholds - since Z scored streams will be analyzed, input threshold as the desired SD. for eachfile = 1:length(data) data(eachfile).threshold3SD = 3; end % Find session transients by directly called in the findSessionTransients_localmin function [data] = findSessionTransients_localmin(data,'sigfiltz_normsession_trimmed','threshold3SD','fs',800,100,2000,0.5,1);","title":"binSessionTransients"},{"location":"functiondocumentation/#exportsessiontransients","text":"Used to create a table of all transient events across all sessions included in the file key and data structure, and exports the table of transient quantification to a csv file. This function depends on the output from findSessionTransients . The creation of a csv file is helpful for users who prefer to run statistical analyses or make plots in other programs than MATLAB, such as R Studio. INPUTS: DATA: This is a structure that contains at least the output from findSessionTransients . WHICHTRANSIENTS: The name (string) of the parent field containing the table of transietns that you want to identify bins for. This is the output of the findSessionTransients function. The name usually follows the convention sessiontransients_WHICHBLTYPE_WHICHTHRESHOLD EXPORTFILEPATH: A string with the path to the folder location where the created table should be saved to. NOTE: The path must end in a forward slash. ADDVARIABLES: A cell array containing any additional variables from the data structure to be added to the transients table. Variables will be added to every row of the output structure. Cell array inputs must be the names of fields in the data structure. At a minimum, this should contain the subject ID. If multiple sessions per subject are included in the data structure, make sure a session ID variable is also included. For example: {'Subject', 'SessionID', 'Treatment'} OPTIONAL INPUTS: * WHICHTRANSIENTSTABLE: The name (string) of the field within WHICHTRANSIENTS that contains the quantification of individual transient events. This input only needs to be specified if not using the format output from the FINDSESSIONTRANSIENTS functions. Default: 'transientquantification' * FILENAME: A string with a custom name for the output csv file. If not specified, the file name will be generated as 'WHICHTRANSIENTS_AllSessionExport_DAY-MONTH-YEAR.csv' OUTPUTS: This function outputs a csv file with all transients for all sessions in the data structure. The file will be output at the specified file path. If the function is called into an object, the table ALLTRANSIENTS will also be saved to an object in the MATLAB workspace. NOTES: The file path must include the full path for the folder including the computer address, and must end in a forward slash. If the file path is not specified properly, the function won't be able to automatically save the csv file. Make sure to add all relevant experimental variables to the ADDVARIABLES list. This includes at a minimum the Subject ID and a session ID, but it's wise to include other key variables to make future analyses easier. Alternatively, you can keep only the Subject ID and a session ID and match the data to the subject and file keys later, which would include all subject and experimental variables. EXAMPLE: % Export transients with added fields for subject and treatment= addvariables = {'Subject','TreatNum','InjType'}; % Prepare variables to append to each transient % To just output the csv file: exportSessionTransients(data,'sessiontransients_blmean_threshold3SD',analysispath,addvariables); % To output the csv file and add the created table to a MATLAB data structure: alltransients = exportSessionTransients(data,'sessiontransients_blmean_threshold3SD',analysispath,addvariables);","title":"exportSessionTransients"},{"location":"functiondocumentation/#visualization-and-plotting-functions","text":"","title":"Visualization and Plotting Functions"},{"location":"functiondocumentation/#plottraces","text":"Main function to plot whole session fiber photometry traces. This function will plot the streams sig, baq, baq_scaled, sigsub, and sigfilt for a single session. Use this function in a loop to plot streams for all sessions in the data structure. This plot function plots the data streams with time in minutes on the x axis. To modify the plot or add additional features like session relevant time stamps, use the plot in a loop. Modified plots must be saved in the external loop. If modifications are not neccesaary, then optional inputs can be specified to directly output and save the plot to a filepath location. INPUTS: DATA: This is a structure that contains at least the data stream you want to analyze, a field with the threshold values, and a field with the sampling rate of the data stream. WHICHFILE: The file number to be plotted. MAINTITLE: The main title (string) to be displayed for the overall plot above the individual tiles. For example, '427 - Treatment: Morphine' OPTIONAL INPUTS: SAVEOUTPUT: Set to 1 to automatically save trace plots as png to the plot file path. Default: 0 PLOTFILEPATH: Required if SAVEOUTPUT is set to 1. The specific path to save the plot to. Note that this must be the entire path from computer address to folder ending in the filename for the specific plot. For example: 'C:\\Users\\rmdon\\Box\\Injection Transients\\Figures\\SessionTraces_427_Morphine.png' OUTPUTS: ALLTRACES: A plot object containing subplots for each input stream. EXAMPLE: Single Session %% Plot the first session and automatically save the output maintitle = append(num2str(data(1).Subject),' - Treatment: ',data(1).InjType); % Create title string for current plot plotfilepath = 'C:\\Users\\rmdon\\Box\\Injection Transients\\Figures\\SessionTraces_427_Morphine.png'; % Create plot file path for the current plot plotTraces(data,1,maintitle,'saveoutput',1,'plotfilepath',plotfilepath); EXAMPLE: All Sessions %% Plot whole session streams for each file for eachfile = 1:length(data) maintitle = append(num2str(data(eachfile).Subject),' - Treatment: ',data(eachfile).InjType); % Create title string for current plot alltraces = plotTraces(data,eachfile,maintitle); for eachtile = 1:5 nexttile(eachtile) xline(data(eachfile).injt(1),'--','Injection','Color','#C40300','FontSize',8) xline(data(eachfile).injt(2),'--','Color','#C40300','FontSize',8) end set(gcf, 'Units', 'inches', 'Position', [0, 0, 8, 9]); plotfilepath = append(figurepath,'SessionTraces_',num2str(data(eachfile).Subject),'_',data(eachfile).InjType,'.png'); exportgraphics(gcf,plotfilepath,'Resolution',300) end","title":"plotTraces"},{"location":"functiondocumentation/#plotffts","text":"Main function to plot whole session fiber photometry FFT frequency magnitude plots. This function will plot the streams sig, baq, baq_scaled, sigsub, and sigfilt for a single session. Use this function in a loop to plot streams for all sessions in the data structure. By default, only frequencies up to 20 hz will be plotted but users can specify an optional input to adjust the cutoff lower or higher, or set to the actual max for the stream FFT. To modify the plot or add additional features, use the plot in a loop. Modified plots must be saved in the external loop. If modifications are not neccesaary, then optional inputs can be specified to directly output and save the plot to a filepath location. INPUTS: DATA: This is a structure that contains at least the data stream you want to analyze, a field with the threshold values, and a field with the sampling rate of the data stream. WHICHFILE: The file number to be plotted. MAINTITLE: The main title (string) to be displayed for the overall plot above the individual tiles. For example, '427 - Treatment: Morphine' WHICHFS: The name (string) of the field that contains the sampling rate of the data streams. OPTIONAL INPUTS: XMAX: The desired frequency cutoff for the x axis (hz). Frequencies above this value will be excluded from the plots. To plot all frequencies, set to actual'. Default: 20 SAVEOUTPUT: Set to 1 to automatically save trace plots as png to the plot file path. Default: 0 PLOTFILEPATH: Required if SAVEOUTPUT is set to 1. The specific path to save the plot to. Note that this must be the entire path from computer address to folder ending in the filename for the specific plot. For example: 'C:\\Users\\rmdon\\Box\\Injection Transients\\Figures\\SessionTraces_427_Morphine.png' OUTPUTS: ALLFFTS: A plot object containing subplots for each input stream. EXAMPLE: Single Session %% Plot the first session and automatically save the output maintitle = append(num2str(data(1).Subject),' - Treatment: ',data(1).InjType); % Create title string for current plot plotfilepath = 'C:\\Users\\rmdon\\Box\\Injection Transients\\Figures\\SessionTraces_427_Morphine.png'; % Create plot file path for the current plot plotTraces(data,1,maintitle,'fs','saveoutput',1,'plotfilepath',plotfilepath); EXAMPLE: All Sessions %% Plot stream FFTs for each file for eachfile = 1:length(data) maintitle = append(num2str(data(eachfile).Subject),' - Treatment: ',data(eachfile).InjType); % Create title string for current plot allffts = plotFFTs(data,eachfile,maintitle); set(gcf, 'Units', 'inches', 'Position', [0, 0, 8, 9]); plotfilepath = append(figurepath,'SessionFFTs_',num2str(data(eachfile).Subject),'_',data(eachfile).InjType,'.png'); exportgraphics(gcf,plotfilepath,'Resolution',300) end","title":"plotFFTs"},{"location":"gettingstarted/","text":"Getting Started with PASTa Here you'll find the quick start guide to set up PASTa with instructions on installation and basic use of the toolbox. Once your device is set up, move to the User Guide for detailed documentation on the use of the PASTa Protocol for analysis. Set Up and Installation PASTa was developed and primarily tested on Windows. Use in other operating systems may require adaptation of functions and analysis example scripts. For Mac users, we've attempted to integrate additional instructions but some troubleshooting may be required. GitHub and GitHub Desktop Install GitHub Desktop if you haven't already. Make an account on GitHub, note that students get access to premium features for free through the student developer pack once verified. Install GitHub Desktop and set up a location for your repositories on your local computer. For newer users, we recommend making a folder on your desktop called \"GitHubRepositories\" and cloning all repositories there. This makes it very easy to locate your repositories. For an overview of how to use GitHub and best practices: https://www.freecodecamp.org/news/introduction-to-git-and-github/ MATLAB Installation Install MATLAB to you computer, including the simulink suite. Functions have been tested and confirmed with MATLAB 2022, 2023, and 2024 releases. PASTa Toolbox Installation","title":"Getting Started"},{"location":"gettingstarted/#getting-started-with-pasta","text":"Here you'll find the quick start guide to set up PASTa with instructions on installation and basic use of the toolbox. Once your device is set up, move to the User Guide for detailed documentation on the use of the PASTa Protocol for analysis.","title":"Getting Started with PASTa"},{"location":"gettingstarted/#set-up-and-installation","text":"PASTa was developed and primarily tested on Windows. Use in other operating systems may require adaptation of functions and analysis example scripts. For Mac users, we've attempted to integrate additional instructions but some troubleshooting may be required.","title":"Set Up and Installation"},{"location":"gettingstarted/#github-and-github-desktop","text":"Install GitHub Desktop if you haven't already. Make an account on GitHub, note that students get access to premium features for free through the student developer pack once verified. Install GitHub Desktop and set up a location for your repositories on your local computer. For newer users, we recommend making a folder on your desktop called \"GitHubRepositories\" and cloning all repositories there. This makes it very easy to locate your repositories. For an overview of how to use GitHub and best practices: https://www.freecodecamp.org/news/introduction-to-git-and-github/","title":"GitHub and GitHub Desktop"},{"location":"gettingstarted/#matlab-installation","text":"Install MATLAB to you computer, including the simulink suite. Functions have been tested and confirmed with MATLAB 2022, 2023, and 2024 releases.","title":"MATLAB Installation"},{"location":"gettingstarted/#pasta-toolbox-installation","text":"","title":"PASTa Toolbox Installation"},{"location":"learningresources/","text":"Learning Resources This page is a compilation of additional resources that may be useful to users that are in the earlier phases of learning to interact with code. While PASTa is written to be approachable and user friendly, learning to interact with coding environments and write new scripts can be challenging. If you have other resources to reccomend, please let us know and we will update this page. Git, GitHub, and GitHub Desktop Getting Started with Git and GitHub Desktop , Article by Codeacademy: https://www.codecademy.com/article/what-is-git-and-github-desktop An Intro to Git and GitHub for Beginners (Tutorial) , Article by HubSpot: https://product.hubspot.com/blog/git-and-github-tutorial-for-beginners Git, GitHub, & GitHub Desktop for beginners , Video by Coder Coder: https://www.youtube.com/watch?v=8Dd7KRpKeaE","title":"Learning Resources"},{"location":"learningresources/#learning-resources","text":"This page is a compilation of additional resources that may be useful to users that are in the earlier phases of learning to interact with code. While PASTa is written to be approachable and user friendly, learning to interact with coding environments and write new scripts can be challenging. If you have other resources to reccomend, please let us know and we will update this page.","title":"Learning Resources"},{"location":"learningresources/#git-github-and-github-desktop","text":"Getting Started with Git and GitHub Desktop , Article by Codeacademy: https://www.codecademy.com/article/what-is-git-and-github-desktop An Intro to Git and GitHub for Beginners (Tutorial) , Article by HubSpot: https://product.hubspot.com/blog/git-and-github-tutorial-for-beginners Git, GitHub, & GitHub Desktop for beginners , Video by Coder Coder: https://www.youtube.com/watch?v=8Dd7KRpKeaE","title":"Git, GitHub, and GitHub Desktop"},{"location":"about/citepasta/","text":"How to Cite PASTa Information on citing the PASTa Protocol coming soon, thanks for checking!","title":"How to Cite PASTa"},{"location":"about/citepasta/#how-to-cite-pasta","text":"Information on citing the PASTa Protocol coming soon, thanks for checking!","title":"How to Cite PASTa"},{"location":"about/license/","text":"License Copyright (C) 2024 Rachel Donka. The PASTa Protocol software and source code is licensed under the GNU General Public License v3. This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. Disclaimer of Warranty: THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \u201cAS IS\u201d WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION. Limitation of Liability: IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. For more information about the GNU General Public License, see the full license at [ https://www.gnu.org/licenses/gpl-3.0.html ]","title":"License"},{"location":"about/license/#license","text":"Copyright (C) 2024 Rachel Donka. The PASTa Protocol software and source code is licensed under the GNU General Public License v3. This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. Disclaimer of Warranty: THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \u201cAS IS\u201d WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION. Limitation of Liability: IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. For more information about the GNU General Public License, see the full license at [ https://www.gnu.org/licenses/gpl-3.0.html ]","title":"License"},{"location":"about/pastateam/","text":"PASTa Team PASTa was developed by the Roitman laboratories at the University of Illinois Chicago. Development Team Rachel Donka , Graduate Student, J Roitman Lab Dr. Maxine Loh , Post Doctoral Fellow, M Roitman Lab Dr. Vaibhav Konanur , Former Graduate Student, M Roitman Lab Dr. Jamie Roitman , Principal Investigator Dr. Mitchell Roitman Maintenance Team Rachel Donka , Graduate Student, J Roitman Lab Dr. Maxine Loh , Post Doctoral Fellow, M Roitman Lab","title":"PASTa Team"},{"location":"about/pastateam/#pasta-team","text":"PASTa was developed by the Roitman laboratories at the University of Illinois Chicago.","title":"PASTa Team"},{"location":"about/pastateam/#development-team","text":"Rachel Donka , Graduate Student, J Roitman Lab Dr. Maxine Loh , Post Doctoral Fellow, M Roitman Lab Dr. Vaibhav Konanur , Former Graduate Student, M Roitman Lab Dr. Jamie Roitman , Principal Investigator Dr. Mitchell Roitman","title":"Development Team"},{"location":"about/pastateam/#maintenance-team","text":"Rachel Donka , Graduate Student, J Roitman Lab Dr. Maxine Loh , Post Doctoral Fellow, M Roitman Lab","title":"Maintenance Team"},{"location":"about/releasenotes/","text":"Version Release Notes Version 0.0 (2024-11-30) Version detailed in pre-print Biorxiv manuscript.","title":"Version Release Notes"},{"location":"about/releasenotes/#version-release-notes","text":"","title":"Version Release Notes"},{"location":"about/releasenotes/#version-00-2024-11-30","text":"Version detailed in pre-print Biorxiv manuscript.","title":"Version 0.0 (2024-11-30)"},{"location":"userguide/datapreparation/","text":"Data Preparation The first stage in the PASTa Protocol is data preparation, which involves associating fiber photometry data with experimental meta data, loading raw data, and extracting and saving the raw data as MATLAB data structures to faciliate future analysis sessions. For data collected with Tucker Davis Technologies equipment and software Synapse , custom functions are included to extract data from raw formats. For data collected with other systems, data must be pre-formatted to match a generic csv file format structure and loaded with provided custom functions, or prepared separately by the user. If your data doesn't match the available load options, please feel free to reach out! Data Organization The PASTa protocol is set up to accomodate any kind of file organization preferred by the user. Organization preference may vary depending on your lab's file storage practices, photometry equipment, or individual projects. TDT Synapse Output Fiber photometry data collected through the software Synapse (Tucker Davis Technologies) is stored in tanks and blocks . Tanks are parent folders created by Synapse for each experiment. Blocks are individual folders for each session containing the actual output data. Stored data cannot be accessed directly via the folder, but rather must be extracted via MATLAB. By default, the tank path is: C:\\TDT\\Synapse\\Tanks. Synapse recognizes experiments and subjects as key categories of information that play a special role in managing data storage and retrieval. Thus, when running the session, it is critical to ensure the correct Experiment profile is selected, and the correct Subject identifier is input for each session. By default, Synapse names data tanks automatically based on experiment name and the start time of the first recording {ExperimentName}-{yymmdd}-{hhmmss}. Blocks of data are named based on subject {SubjectName}-{yymmdd}-{hhmmss} for each recording session and the start time. Synapse will save a new Tank for every day unless you change the default setting. Click Menu at the top of the bar, then Preferences. Under the Data Saving tab, make sure \"New Tank Each Day\" is unchecked. Experiment Key Creation To accomodate a variety of file organization structures, users can first create two csv files containing the information necessary to access raw data, and experimental metadata to match to raw photometry data. MATLAB can access raw data folders stored either locally or in a cloud-based storage app like Box or Dropbox. To faciliate analysis, users can create two keys as csv files: a subject key and a file key. In the PASTa protocol, these files will be knit together to pair subject specific information with each individual session of data, preventing the need for manual repeated entry of subject specific information and reduce the time burden of properly maintaining and including experimental metadata factors like subject traits, treatments, and experimental equipment. First, locate the raw files to be analyzed in your file organization structure. Prepare a folder for extracted raw data to be saved to. This should be separate from your tank folder / raw data storage, and will eventually contain the extracted data sets for each session as MATLAB structures to facilitate efficient data processing in future analysis sessions. Subject Key The subject key should contain information about each subject that is constant and unchanging, such as SubjectID, sex, date of birth, fiber location, sensor, experimental group, and any other user specificed information. For example: File Key The file key should contain information about each unique session / file to be analyzed. At a minimum, this must include the SubjectID, folder name, raw folder location, and desired location for the raw data to be exported to. REQUIRED VARIABLES: SubjectID: Unique identifier of the subject. This fieldname should match the first field in the subject key, and inputs for each subject have to match the subject key for subject specific data to be properly associated to fiber photometry data. Folder: The name of the folder containing the raw data. RawFolderPath : The path to the location where the raw data folder is saved for each specific session. All file paths should be specified in the file key WITHOUT the computer user specific portion of the path. This facilitates analysis across multiple devices or cloud storage solutions without manual edits to the file key. Ensure the specified path ends in a forward slash. For example , a file saved to a specific device at the path \"C:\\Users\\rmdon\\Box\\RawData\\\" should be specified as \"Box\\RawData\\\" . ExtractedFolderPath: The path to the location where you would like the extracted data structure to be saved. This should be different than the raw data storage location. All file paths should be specified in the file key WITHOUT the computer and user specific portion of the path. This facilitates analysis across multiple devices or cloud storage solutions without manual edits to the file key. Ensure the specified path ends in a forward slash. For example , a file saved to a specific device at the path \"C:\\Users\\rmdon\\Box\\ExtractedData\\\" should be specified as \"Box\\ExtractedData\\\" . Any additional fields can be included such as equipment information, recording power, session condition, drug treatments, body weight, and any other variables that are specific to that one session. Note that the only field name that should overlap with a field name in the subject key is SubjectID . For example: Prepare MATLAB First, prepare MATLAB by setting up key paths to stored data, locations to save outputs, and add functions folders to the MATLAB path. Code example: FUNCTION: LoadKeys loadKeys joins the individual subject information to the file key with the data for each session. Additionally, loadkeys appends the unique computer user portion of the file navigation path to the beginning and the Folder name to the end of the raw and extracted folder paths specified in the file key. This creates the full path to the location of each session's data. For example, \"C:\\Users\\rmdon\\Box\\RawData\\Subject1-240101-121500\" . The created experiment key should be output into a data structure called experimentkey . REQUIRED INPUTS: computeruserpath: A string containing the portion of the filepath that is unique to the specific computer being used for analysis. This input allows users to easily switch between computers without updating the individual paths in the file key. subjectkeyname: A string containing the name of the csv file that contains the subject key file name, including the .csv extention at the end. If no subject is needed (such as if every subject only has one session of photometry data), then subjectkeyname can be left empty (set to ''). filekeyname: A string containing the name of the csv file that contains the file key file name, including the .csv extention at the end. Code example: Extracting the Data Prior to beginning analysis, individual session data should be extracted and saved as MATLAB data structures. This makes the process of loading data at the start of each analysis session significantly faster. When the raw data is extracted, trimming will be applied by default. This removes the first and last 5 seconds of the session to remove large fluctuations in output signal that occur when the hardware is turned on and off. The number of seconds trimmed can be adjusted by overriding the default. FUNCTION: extractdata Multiple options are available to extract the data, and should be used depending on the method by which the data was collected, both documented in detail below. Several customized functions are available to extract and format the data for easy processing and analysis. Data collected with TDT can be extracted with custom functions. For all other systems, utilize the generic csv format. The required inputs are the same for all extract data functions. REQUIRED INPUTS: rawfolderpaths: A string array containing the full paths to the folder locations of raw data to be extracted for each session. This should be formatted as a single column with each full path in a separate row. This is easy to create from the experiment key (see below for an example). extractedfolderpaths: A string array containing the full paths to the folder locations where extracted data should be saved for each session (including the individual session name). As with the rawfolderpaths, this should be formatted as a single column with each full path in a separate row and can easily be created from the experiment key (see below for an example). sigstreamnames: A cell array containing the strings with the names of all streams to be treated as signal. This allows for flexibility if different photometry rigs have differing naming conventions for the signal stream. Include all signal stream name variations in this cell array. Note that only one stream per file can be treated as signal. baqstreamnames: A cell array containing the strings with the names of all streams to be treated as background. This allows for flexibility if different photometry rigs have differing naming conventions for the background stream. Include all background stream name variations in this cell array. Note that only one stream per file can be treated as signal. sigstreamnames: A cell array containing the strings with the names of all streams to be treated as signal. This allows for flexibility if different photometry rigs have differing naming conventions for signal stream. Include all signal stream name variations in this cell array. Note that only one stream per file can be treated as signal. OPTIONAL INPUTS: trim: Number of seconds to remove at the beginning and end of the session. This defaults to 5 seconds. skipexisting: This input allows users to toggle if previously extracted raw data files are re-extracted. By default, previously extracted files will be skipped (skipexisting = 1). To override and re-extract all files, set skipexisting = 0. Extracted raw data files are saved to the extracted folder path as individual MATLAB structures. Code example: Loading the Data After raw data is extracted, it can be matched to the experimentkey to associate any subject and session metadata with the photometry data. All sessions will be loaded into one data structure (typically called rawdata ), to ensure that all sessions are analyzed in the same way throughout following steps of the protocol. Each session of data is a row within the data structure. Regardless of hardware set up, all extracted files can be loaded with the function LoadKeydata . FUNCTION: loadKeydata REQUIRED INPUTS: experimentkey: Data structure created by the LoadKeys function, containing at least the field ExtractedFolderPath with the full path to each individual session of data to be loaded. Code example: Cropping the Data The final step in data preparation is optional. Photometry recording may start a few seconds before the experiment begins, such as in cases where users have to initiate hardware for operant boxes separately, and after the experiment ends. Additionally, users may want to remove the first few minutes of each session due to the higher rate of photobleaching before the signal stabilizes. If desired, data can be cropped with the function cropFPdata , which uses user derived session start and session end indexes to crop data streams and adjust any event epochs (timestamps) to maintain the relationship in time. Index Preparation If timestamps for session start and end are included in the raw data collection, then these fields can be used as the cropping start and end points. If not, users must first determine the appropriate start and end points from whatever timestamps are relevant. For example, in the example analysis provided the session is cropped to 15 minutes before the first injection time stamp, and 60 minutes after the second injection time stamp. Code example of preparing the start and end indices: FUNCTION: cropFPdata REQUIRED INPUTS: data: Data structure created by the LoadKeyData function. Each session should be a separate row. The data structure must containing at least the fields specified in the additional inputs. whichcropstart: A string containing the name of the field with the locations of the session start indices. Everything before the start index will be cropped. whichcropend: A string containing the name of the field with the locations of the session end indices. Everything after the end index will be cropped. whichstreams: A cell array containing the field names of all the streams to be cropped. This should include both the signal and the background streams. OPTIONAL INPUTS: whichepocs: A cell array containing the field names of all the epochs (time stamps) to be adjusted. This input can contain as many inputs as the experimental paradigm requires, and each timestamp will be adjusted by subtracting the start index - 1. Code example of cropping: After data preparation is complete, move to Signal Processing .","title":"Data Preparation"},{"location":"userguide/datapreparation/#data-preparation","text":"The first stage in the PASTa Protocol is data preparation, which involves associating fiber photometry data with experimental meta data, loading raw data, and extracting and saving the raw data as MATLAB data structures to faciliate future analysis sessions. For data collected with Tucker Davis Technologies equipment and software Synapse , custom functions are included to extract data from raw formats. For data collected with other systems, data must be pre-formatted to match a generic csv file format structure and loaded with provided custom functions, or prepared separately by the user. If your data doesn't match the available load options, please feel free to reach out!","title":"Data Preparation"},{"location":"userguide/datapreparation/#data-organization","text":"The PASTa protocol is set up to accomodate any kind of file organization preferred by the user. Organization preference may vary depending on your lab's file storage practices, photometry equipment, or individual projects.","title":"Data Organization"},{"location":"userguide/datapreparation/#tdt-synapse-output","text":"Fiber photometry data collected through the software Synapse (Tucker Davis Technologies) is stored in tanks and blocks . Tanks are parent folders created by Synapse for each experiment. Blocks are individual folders for each session containing the actual output data. Stored data cannot be accessed directly via the folder, but rather must be extracted via MATLAB. By default, the tank path is: C:\\TDT\\Synapse\\Tanks. Synapse recognizes experiments and subjects as key categories of information that play a special role in managing data storage and retrieval. Thus, when running the session, it is critical to ensure the correct Experiment profile is selected, and the correct Subject identifier is input for each session. By default, Synapse names data tanks automatically based on experiment name and the start time of the first recording {ExperimentName}-{yymmdd}-{hhmmss}. Blocks of data are named based on subject {SubjectName}-{yymmdd}-{hhmmss} for each recording session and the start time. Synapse will save a new Tank for every day unless you change the default setting. Click Menu at the top of the bar, then Preferences. Under the Data Saving tab, make sure \"New Tank Each Day\" is unchecked.","title":"TDT Synapse Output"},{"location":"userguide/datapreparation/#experiment-key-creation","text":"To accomodate a variety of file organization structures, users can first create two csv files containing the information necessary to access raw data, and experimental metadata to match to raw photometry data. MATLAB can access raw data folders stored either locally or in a cloud-based storage app like Box or Dropbox. To faciliate analysis, users can create two keys as csv files: a subject key and a file key. In the PASTa protocol, these files will be knit together to pair subject specific information with each individual session of data, preventing the need for manual repeated entry of subject specific information and reduce the time burden of properly maintaining and including experimental metadata factors like subject traits, treatments, and experimental equipment. First, locate the raw files to be analyzed in your file organization structure. Prepare a folder for extracted raw data to be saved to. This should be separate from your tank folder / raw data storage, and will eventually contain the extracted data sets for each session as MATLAB structures to facilitate efficient data processing in future analysis sessions.","title":"Experiment Key Creation"},{"location":"userguide/datapreparation/#subject-key","text":"The subject key should contain information about each subject that is constant and unchanging, such as SubjectID, sex, date of birth, fiber location, sensor, experimental group, and any other user specificed information. For example:","title":"Subject Key"},{"location":"userguide/datapreparation/#file-key","text":"The file key should contain information about each unique session / file to be analyzed. At a minimum, this must include the SubjectID, folder name, raw folder location, and desired location for the raw data to be exported to. REQUIRED VARIABLES: SubjectID: Unique identifier of the subject. This fieldname should match the first field in the subject key, and inputs for each subject have to match the subject key for subject specific data to be properly associated to fiber photometry data. Folder: The name of the folder containing the raw data. RawFolderPath : The path to the location where the raw data folder is saved for each specific session. All file paths should be specified in the file key WITHOUT the computer user specific portion of the path. This facilitates analysis across multiple devices or cloud storage solutions without manual edits to the file key. Ensure the specified path ends in a forward slash. For example , a file saved to a specific device at the path \"C:\\Users\\rmdon\\Box\\RawData\\\" should be specified as \"Box\\RawData\\\" . ExtractedFolderPath: The path to the location where you would like the extracted data structure to be saved. This should be different than the raw data storage location. All file paths should be specified in the file key WITHOUT the computer and user specific portion of the path. This facilitates analysis across multiple devices or cloud storage solutions without manual edits to the file key. Ensure the specified path ends in a forward slash. For example , a file saved to a specific device at the path \"C:\\Users\\rmdon\\Box\\ExtractedData\\\" should be specified as \"Box\\ExtractedData\\\" . Any additional fields can be included such as equipment information, recording power, session condition, drug treatments, body weight, and any other variables that are specific to that one session. Note that the only field name that should overlap with a field name in the subject key is SubjectID . For example:","title":"File Key"},{"location":"userguide/datapreparation/#prepare-matlab","text":"First, prepare MATLAB by setting up key paths to stored data, locations to save outputs, and add functions folders to the MATLAB path. Code example:","title":"Prepare MATLAB"},{"location":"userguide/datapreparation/#function-loadkeys","text":"loadKeys joins the individual subject information to the file key with the data for each session. Additionally, loadkeys appends the unique computer user portion of the file navigation path to the beginning and the Folder name to the end of the raw and extracted folder paths specified in the file key. This creates the full path to the location of each session's data. For example, \"C:\\Users\\rmdon\\Box\\RawData\\Subject1-240101-121500\" . The created experiment key should be output into a data structure called experimentkey . REQUIRED INPUTS: computeruserpath: A string containing the portion of the filepath that is unique to the specific computer being used for analysis. This input allows users to easily switch between computers without updating the individual paths in the file key. subjectkeyname: A string containing the name of the csv file that contains the subject key file name, including the .csv extention at the end. If no subject is needed (such as if every subject only has one session of photometry data), then subjectkeyname can be left empty (set to ''). filekeyname: A string containing the name of the csv file that contains the file key file name, including the .csv extention at the end. Code example:","title":"FUNCTION: LoadKeys"},{"location":"userguide/datapreparation/#extracting-the-data","text":"Prior to beginning analysis, individual session data should be extracted and saved as MATLAB data structures. This makes the process of loading data at the start of each analysis session significantly faster. When the raw data is extracted, trimming will be applied by default. This removes the first and last 5 seconds of the session to remove large fluctuations in output signal that occur when the hardware is turned on and off. The number of seconds trimmed can be adjusted by overriding the default.","title":"Extracting the Data"},{"location":"userguide/datapreparation/#function-extractdata","text":"Multiple options are available to extract the data, and should be used depending on the method by which the data was collected, both documented in detail below. Several customized functions are available to extract and format the data for easy processing and analysis. Data collected with TDT can be extracted with custom functions. For all other systems, utilize the generic csv format. The required inputs are the same for all extract data functions. REQUIRED INPUTS: rawfolderpaths: A string array containing the full paths to the folder locations of raw data to be extracted for each session. This should be formatted as a single column with each full path in a separate row. This is easy to create from the experiment key (see below for an example). extractedfolderpaths: A string array containing the full paths to the folder locations where extracted data should be saved for each session (including the individual session name). As with the rawfolderpaths, this should be formatted as a single column with each full path in a separate row and can easily be created from the experiment key (see below for an example). sigstreamnames: A cell array containing the strings with the names of all streams to be treated as signal. This allows for flexibility if different photometry rigs have differing naming conventions for the signal stream. Include all signal stream name variations in this cell array. Note that only one stream per file can be treated as signal. baqstreamnames: A cell array containing the strings with the names of all streams to be treated as background. This allows for flexibility if different photometry rigs have differing naming conventions for the background stream. Include all background stream name variations in this cell array. Note that only one stream per file can be treated as signal. sigstreamnames: A cell array containing the strings with the names of all streams to be treated as signal. This allows for flexibility if different photometry rigs have differing naming conventions for signal stream. Include all signal stream name variations in this cell array. Note that only one stream per file can be treated as signal. OPTIONAL INPUTS: trim: Number of seconds to remove at the beginning and end of the session. This defaults to 5 seconds. skipexisting: This input allows users to toggle if previously extracted raw data files are re-extracted. By default, previously extracted files will be skipped (skipexisting = 1). To override and re-extract all files, set skipexisting = 0. Extracted raw data files are saved to the extracted folder path as individual MATLAB structures. Code example:","title":"FUNCTION: extractdata"},{"location":"userguide/datapreparation/#loading-the-data","text":"After raw data is extracted, it can be matched to the experimentkey to associate any subject and session metadata with the photometry data. All sessions will be loaded into one data structure (typically called rawdata ), to ensure that all sessions are analyzed in the same way throughout following steps of the protocol. Each session of data is a row within the data structure. Regardless of hardware set up, all extracted files can be loaded with the function LoadKeydata .","title":"Loading the Data"},{"location":"userguide/datapreparation/#function-loadkeydata","text":"REQUIRED INPUTS: experimentkey: Data structure created by the LoadKeys function, containing at least the field ExtractedFolderPath with the full path to each individual session of data to be loaded. Code example:","title":"FUNCTION: loadKeydata"},{"location":"userguide/datapreparation/#cropping-the-data","text":"The final step in data preparation is optional. Photometry recording may start a few seconds before the experiment begins, such as in cases where users have to initiate hardware for operant boxes separately, and after the experiment ends. Additionally, users may want to remove the first few minutes of each session due to the higher rate of photobleaching before the signal stabilizes. If desired, data can be cropped with the function cropFPdata , which uses user derived session start and session end indexes to crop data streams and adjust any event epochs (timestamps) to maintain the relationship in time.","title":"Cropping the Data"},{"location":"userguide/datapreparation/#index-preparation","text":"If timestamps for session start and end are included in the raw data collection, then these fields can be used as the cropping start and end points. If not, users must first determine the appropriate start and end points from whatever timestamps are relevant. For example, in the example analysis provided the session is cropped to 15 minutes before the first injection time stamp, and 60 minutes after the second injection time stamp. Code example of preparing the start and end indices:","title":"Index Preparation"},{"location":"userguide/datapreparation/#function-cropfpdata","text":"REQUIRED INPUTS: data: Data structure created by the LoadKeyData function. Each session should be a separate row. The data structure must containing at least the fields specified in the additional inputs. whichcropstart: A string containing the name of the field with the locations of the session start indices. Everything before the start index will be cropped. whichcropend: A string containing the name of the field with the locations of the session end indices. Everything after the end index will be cropped. whichstreams: A cell array containing the field names of all the streams to be cropped. This should include both the signal and the background streams. OPTIONAL INPUTS: whichepocs: A cell array containing the field names of all the epochs (time stamps) to be adjusted. This input can contain as many inputs as the experimental paradigm requires, and each timestamp will be adjusted by subtracting the start index - 1. Code example of cropping: After data preparation is complete, move to Signal Processing .","title":"FUNCTION: cropFPdata"},{"location":"userguide/plotdata/","text":"Plot Data The final stage in the PASTa Protocol is data visualization For data collected with other systems, data must be pre-formatted to match a generic csv file format structure and loaded with provided custom functions, or prepared separately by the user. If your data doesn't match the available load options, please feel free to reach out! Data Organization The PASTa protocol is set up to accomodate any kind of file organization preferred by the user. Organization preference may vary depending on your lab's file storage practices, photometry equipment, or individual projects. TDT Synapse Output Fiber photometry data collected through the software Synapse (Tucker Davis Technologies) is stored in tanks and blocks . Tanks are parent folders created by Synapse for each experiment. Blocks are individual folders for each session containing the actual output data. Stored data cannot be accessed directly via the folder, but rather must be extracted via MATLAB. By default, the tank path is: C:\\TDT\\Synapse\\Tanks. Synapse recognizes experiments and subjects as key categories of information that play a special role in managing data storage and retrieval. Thus, when running the session, it is critical to ensure the correct Experiment profile is selected, and the correct Subject identifier is input for each session. By default, Synapse names data tanks automatically based on experiment name and the start time of the first recording {ExperimentName}-{yymmdd}-{hhmmss}. Blocks of data are named based on subject {SubjectName}-{yymmdd}-{hhmmss} for each recording session and the start time. Synapse will save a new Tank for every day unless you change the default setting. Click Menu at the top of the bar, then Preferences. Under the Data Saving tab, make sure \"New Tank Each Day\" is unchecked. Experiment Key Creation To accomodate a variety of file organization structures, users can first create two csv files containing the information necessary to access raw data, and experimental metadata to match to raw photometry data. MATLAB can access raw data folders stored either locally or in a cloud-based storage app like Box or Dropbox. To faciliate analysis, users can create two keys as csv files: a subject key and a file key. In the PASTa protocol, these files will be knit together to pair subject specific information with each individual session of data, preventing the need for manual repeated entry of subject specific information and reduce the time burden of properly maintaining and including experimental metadata factors like subject traits, treatments, and experimental equipment. First, locate the raw files to be analyzed in your file organization structure. Prepare a folder for extracted raw data to be saved to. This should be separate from your tank folder / raw data storage, and will eventually contain the extracted data sets for each session as MATLAB structures to facilitate efficient data processing in future analysis sessions. Subject Key The subject key should contain information about each subject that is constant and unchanging, such as SubjectID, sex, date of birth, fiber location, sensor, experimental group, and any other user specificed information. For example: File Key The file key should contain information about each unique session / file to be analyzed. At a minimum, this must include the SubjectID, folder name, raw folder location, and desired location for the raw data to be exported to. REQUIRED VARIABLES: SubjectID: Unique identifier of the subject. This fieldname should match the first field in the subject key, and inputs for each subject have to match the subject key for subject specific data to be properly associated to fiber photometry data. Folder: The name of the folder containing the raw data. RawFolderPath : The path to the location where the raw data folder is saved for each specific session. All file paths should be specified in the file key WITHOUT the computer user specific portion of the path. This facilitates analysis across multiple devices or cloud storage solutions without manual edits to the file key. Ensure the specified path ends in a forward slash. For example , a file saved to a specific device at the path \"C:\\Users\\rmdon\\Box\\RawData\\\" should be specified as \"Box\\RawData\\\" . ExtractedFolderPath: The path to the location where you would like the extracted data structure to be saved. This should be different than the raw data storage location. All file paths should be specified in the file key WITHOUT the computer and user specific portion of the path. This facilitates analysis across multiple devices or cloud storage solutions without manual edits to the file key. Ensure the specified path ends in a forward slash. For example , a file saved to a specific device at the path \"C:\\Users\\rmdon\\Box\\ExtractedData\\\" should be specified as \"Box\\ExtractedData\\\" . Any additional fields can be included such as equipment information, recording power, session condition, drug treatments, body weight, and any other variables that are specific to that one session. Note that the only field name that should overlap with a field name in the subject key is SubjectID . For example: Prepare MATLAB First, prepare MATLAB by setting up key paths to stored data, locations to save outputs, and add functions folders to the MATLAB path. Code example: FUNCTION: LoadKeys loadKeys joins the individual subject information to the file key with the data for each session. Additionally, loadkeys appends the unique computer user portion of the file navigation path to the beginning and the Folder name to the end of the raw and extracted folder paths specified in the file key. This creates the full path to the location of each session's data. For example, \"C:\\Users\\rmdon\\Box\\RawData\\Subject1-240101-121500\" . The created experiment key should be output into a data structure called experimentkey . REQUIRED INPUTS: computeruserpath: A string containing the portion of the filepath that is unique to the specific computer being used for analysis. This input allows users to easily switch between computers without updating the individual paths in the file key. subjectkeyname: A string containing the name of the csv file that contains the subject key file name, including the .csv extention at the end. If no subject is needed (such as if every subject only has one session of photometry data), then subjectkeyname can be left empty (set to ''). filekeyname: A string containing the name of the csv file that contains the file key file name, including the .csv extention at the end. Code example: Extracting the Data Prior to beginning analysis, individual session data should be extracted and saved as MATLAB data structures. This makes the process of loading data at the start of each analysis session significantly faster. When the raw data is extracted, trimming will be applied by default. This removes the first and last 5 seconds of the session to remove large fluctuations in output signal that occur when the hardware is turned on and off. The number of seconds trimmed can be adjusted by overriding the default. FUNCTION: extractdata Multiple options are available to extract the data, and should be used depending on the method by which the data was collected, both documented in detail below. Several customized functions are available to extract and format the data for easy processing and analysis. Data collected with TDT can be extracted with custom functions. For all other systems, utilize the generic csv format. The required inputs are the same for all extract data functions. REQUIRED INPUTS: rawfolderpaths: A string array containing the full paths to the folder locations of raw data to be extracted for each session. This should be formatted as a single column with each full path in a separate row. This is easy to create from the experiment key (see below for an example). extractedfolderpaths: A string array containing the full paths to the folder locations where extracted data should be saved for each session (including the individual session name). As with the rawfolderpaths, this should be formatted as a single column with each full path in a separate row and can easily be created from the experiment key (see below for an example). sigstreamnames: A cell array containing the strings with the names of all streams to be treated as signal. This allows for flexibility if different photometry rigs have differing naming conventions for the signal stream. Include all signal stream name variations in this cell array. Note that only one stream per file can be treated as signal. baqstreamnames: A cell array containing the strings with the names of all streams to be treated as background. This allows for flexibility if different photometry rigs have differing naming conventions for the background stream. Include all background stream name variations in this cell array. Note that only one stream per file can be treated as signal. sigstreamnames: A cell array containing the strings with the names of all streams to be treated as signal. This allows for flexibility if different photometry rigs have differing naming conventions for signal stream. Include all signal stream name variations in this cell array. Note that only one stream per file can be treated as signal. OPTIONAL INPUTS: trim: Number of seconds to remove at the beginning and end of the session. This defaults to 5 seconds. skipexisting: This input allows users to toggle if previously extracted raw data files are re-extracted. By default, previously extracted files will be skipped (skipexisting = 1). To override and re-extract all files, set skipexisting = 0. Extracted raw data files are saved to the extracted folder path as individual MATLAB structures. Code example: Loading the Data After raw data is extracted, it can be matched to the experimentkey to associate any subject and session metadata with the photometry data. All sessions will be loaded into one data structure (typically called rawdata ), to ensure that all sessions are analyzed in the same way throughout following steps of the protocol. Each session of data is a row within the data structure. Regardless of hardware set up, all extracted files can be loaded with the function LoadKeydata . FUNCTION: loadKeydata REQUIRED INPUTS: experimentkey: Data structure created by the LoadKeys function, containing at least the field ExtractedFolderPath with the full path to each individual session of data to be loaded. Code example: Cropping the Data The final step in data preparation is optional. Photometry recording may start a few seconds before the experiment begins, such as in cases where users have to initiate hardware for operant boxes separately, and after the experiment ends. Additionally, users may want to remove the first few minutes of each session due to the higher rate of photobleaching before the signal stabilizes. If desired, data can be cropped with the function cropFPdata , which uses user derived session start and session end indexes to crop data streams and adjust any event epochs (timestamps) to maintain the relationship in time. Index Preparation If timestamps for session start and end are included in the raw data collection, then these fields can be used as the cropping start and end points. If not, users must first determine the appropriate start and end points from whatever timestamps are relevant. For example, in the example analysis provided the session is cropped to 15 minutes before the first injection time stamp, and 60 minutes after the second injection time stamp. Code example of preparing the start and end indices: FUNCTION: cropFPdata REQUIRED INPUTS: data: Data structure created by the LoadKeyData function. Each session should be a separate row. The data structure must containing at least the fields specified in the additional inputs. whichcropstart: A string containing the name of the field with the locations of the session start indices. Everything before the start index will be cropped. whichcropend: A string containing the name of the field with the locations of the session end indices. Everything after the end index will be cropped. whichstreams: A cell array containing the field names of all the streams to be cropped. This should include both the signal and the background streams. OPTIONAL INPUTS: whichepocs: A cell array containing the field names of all the epochs (time stamps) to be adjusted. This input can contain as many inputs as the experimental paradigm requires, and each timestamp will be adjusted by subtracting the start index - 1. Code example of cropping: After data preparation is complete, move to Signal Processing .","title":"Data Visualization"},{"location":"userguide/plotdata/#plot-data","text":"The final stage in the PASTa Protocol is data visualization For data collected with other systems, data must be pre-formatted to match a generic csv file format structure and loaded with provided custom functions, or prepared separately by the user. If your data doesn't match the available load options, please feel free to reach out!","title":"Plot Data"},{"location":"userguide/plotdata/#data-organization","text":"The PASTa protocol is set up to accomodate any kind of file organization preferred by the user. Organization preference may vary depending on your lab's file storage practices, photometry equipment, or individual projects.","title":"Data Organization"},{"location":"userguide/plotdata/#tdt-synapse-output","text":"Fiber photometry data collected through the software Synapse (Tucker Davis Technologies) is stored in tanks and blocks . Tanks are parent folders created by Synapse for each experiment. Blocks are individual folders for each session containing the actual output data. Stored data cannot be accessed directly via the folder, but rather must be extracted via MATLAB. By default, the tank path is: C:\\TDT\\Synapse\\Tanks. Synapse recognizes experiments and subjects as key categories of information that play a special role in managing data storage and retrieval. Thus, when running the session, it is critical to ensure the correct Experiment profile is selected, and the correct Subject identifier is input for each session. By default, Synapse names data tanks automatically based on experiment name and the start time of the first recording {ExperimentName}-{yymmdd}-{hhmmss}. Blocks of data are named based on subject {SubjectName}-{yymmdd}-{hhmmss} for each recording session and the start time. Synapse will save a new Tank for every day unless you change the default setting. Click Menu at the top of the bar, then Preferences. Under the Data Saving tab, make sure \"New Tank Each Day\" is unchecked.","title":"TDT Synapse Output"},{"location":"userguide/plotdata/#experiment-key-creation","text":"To accomodate a variety of file organization structures, users can first create two csv files containing the information necessary to access raw data, and experimental metadata to match to raw photometry data. MATLAB can access raw data folders stored either locally or in a cloud-based storage app like Box or Dropbox. To faciliate analysis, users can create two keys as csv files: a subject key and a file key. In the PASTa protocol, these files will be knit together to pair subject specific information with each individual session of data, preventing the need for manual repeated entry of subject specific information and reduce the time burden of properly maintaining and including experimental metadata factors like subject traits, treatments, and experimental equipment. First, locate the raw files to be analyzed in your file organization structure. Prepare a folder for extracted raw data to be saved to. This should be separate from your tank folder / raw data storage, and will eventually contain the extracted data sets for each session as MATLAB structures to facilitate efficient data processing in future analysis sessions.","title":"Experiment Key Creation"},{"location":"userguide/plotdata/#subject-key","text":"The subject key should contain information about each subject that is constant and unchanging, such as SubjectID, sex, date of birth, fiber location, sensor, experimental group, and any other user specificed information. For example:","title":"Subject Key"},{"location":"userguide/plotdata/#file-key","text":"The file key should contain information about each unique session / file to be analyzed. At a minimum, this must include the SubjectID, folder name, raw folder location, and desired location for the raw data to be exported to. REQUIRED VARIABLES: SubjectID: Unique identifier of the subject. This fieldname should match the first field in the subject key, and inputs for each subject have to match the subject key for subject specific data to be properly associated to fiber photometry data. Folder: The name of the folder containing the raw data. RawFolderPath : The path to the location where the raw data folder is saved for each specific session. All file paths should be specified in the file key WITHOUT the computer user specific portion of the path. This facilitates analysis across multiple devices or cloud storage solutions without manual edits to the file key. Ensure the specified path ends in a forward slash. For example , a file saved to a specific device at the path \"C:\\Users\\rmdon\\Box\\RawData\\\" should be specified as \"Box\\RawData\\\" . ExtractedFolderPath: The path to the location where you would like the extracted data structure to be saved. This should be different than the raw data storage location. All file paths should be specified in the file key WITHOUT the computer and user specific portion of the path. This facilitates analysis across multiple devices or cloud storage solutions without manual edits to the file key. Ensure the specified path ends in a forward slash. For example , a file saved to a specific device at the path \"C:\\Users\\rmdon\\Box\\ExtractedData\\\" should be specified as \"Box\\ExtractedData\\\" . Any additional fields can be included such as equipment information, recording power, session condition, drug treatments, body weight, and any other variables that are specific to that one session. Note that the only field name that should overlap with a field name in the subject key is SubjectID . For example:","title":"File Key"},{"location":"userguide/plotdata/#prepare-matlab","text":"First, prepare MATLAB by setting up key paths to stored data, locations to save outputs, and add functions folders to the MATLAB path. Code example:","title":"Prepare MATLAB"},{"location":"userguide/plotdata/#function-loadkeys","text":"loadKeys joins the individual subject information to the file key with the data for each session. Additionally, loadkeys appends the unique computer user portion of the file navigation path to the beginning and the Folder name to the end of the raw and extracted folder paths specified in the file key. This creates the full path to the location of each session's data. For example, \"C:\\Users\\rmdon\\Box\\RawData\\Subject1-240101-121500\" . The created experiment key should be output into a data structure called experimentkey . REQUIRED INPUTS: computeruserpath: A string containing the portion of the filepath that is unique to the specific computer being used for analysis. This input allows users to easily switch between computers without updating the individual paths in the file key. subjectkeyname: A string containing the name of the csv file that contains the subject key file name, including the .csv extention at the end. If no subject is needed (such as if every subject only has one session of photometry data), then subjectkeyname can be left empty (set to ''). filekeyname: A string containing the name of the csv file that contains the file key file name, including the .csv extention at the end. Code example:","title":"FUNCTION: LoadKeys"},{"location":"userguide/plotdata/#extracting-the-data","text":"Prior to beginning analysis, individual session data should be extracted and saved as MATLAB data structures. This makes the process of loading data at the start of each analysis session significantly faster. When the raw data is extracted, trimming will be applied by default. This removes the first and last 5 seconds of the session to remove large fluctuations in output signal that occur when the hardware is turned on and off. The number of seconds trimmed can be adjusted by overriding the default.","title":"Extracting the Data"},{"location":"userguide/plotdata/#function-extractdata","text":"Multiple options are available to extract the data, and should be used depending on the method by which the data was collected, both documented in detail below. Several customized functions are available to extract and format the data for easy processing and analysis. Data collected with TDT can be extracted with custom functions. For all other systems, utilize the generic csv format. The required inputs are the same for all extract data functions. REQUIRED INPUTS: rawfolderpaths: A string array containing the full paths to the folder locations of raw data to be extracted for each session. This should be formatted as a single column with each full path in a separate row. This is easy to create from the experiment key (see below for an example). extractedfolderpaths: A string array containing the full paths to the folder locations where extracted data should be saved for each session (including the individual session name). As with the rawfolderpaths, this should be formatted as a single column with each full path in a separate row and can easily be created from the experiment key (see below for an example). sigstreamnames: A cell array containing the strings with the names of all streams to be treated as signal. This allows for flexibility if different photometry rigs have differing naming conventions for the signal stream. Include all signal stream name variations in this cell array. Note that only one stream per file can be treated as signal. baqstreamnames: A cell array containing the strings with the names of all streams to be treated as background. This allows for flexibility if different photometry rigs have differing naming conventions for the background stream. Include all background stream name variations in this cell array. Note that only one stream per file can be treated as signal. sigstreamnames: A cell array containing the strings with the names of all streams to be treated as signal. This allows for flexibility if different photometry rigs have differing naming conventions for signal stream. Include all signal stream name variations in this cell array. Note that only one stream per file can be treated as signal. OPTIONAL INPUTS: trim: Number of seconds to remove at the beginning and end of the session. This defaults to 5 seconds. skipexisting: This input allows users to toggle if previously extracted raw data files are re-extracted. By default, previously extracted files will be skipped (skipexisting = 1). To override and re-extract all files, set skipexisting = 0. Extracted raw data files are saved to the extracted folder path as individual MATLAB structures. Code example:","title":"FUNCTION: extractdata"},{"location":"userguide/plotdata/#loading-the-data","text":"After raw data is extracted, it can be matched to the experimentkey to associate any subject and session metadata with the photometry data. All sessions will be loaded into one data structure (typically called rawdata ), to ensure that all sessions are analyzed in the same way throughout following steps of the protocol. Each session of data is a row within the data structure. Regardless of hardware set up, all extracted files can be loaded with the function LoadKeydata .","title":"Loading the Data"},{"location":"userguide/plotdata/#function-loadkeydata","text":"REQUIRED INPUTS: experimentkey: Data structure created by the LoadKeys function, containing at least the field ExtractedFolderPath with the full path to each individual session of data to be loaded. Code example:","title":"FUNCTION: loadKeydata"},{"location":"userguide/plotdata/#cropping-the-data","text":"The final step in data preparation is optional. Photometry recording may start a few seconds before the experiment begins, such as in cases where users have to initiate hardware for operant boxes separately, and after the experiment ends. Additionally, users may want to remove the first few minutes of each session due to the higher rate of photobleaching before the signal stabilizes. If desired, data can be cropped with the function cropFPdata , which uses user derived session start and session end indexes to crop data streams and adjust any event epochs (timestamps) to maintain the relationship in time.","title":"Cropping the Data"},{"location":"userguide/plotdata/#index-preparation","text":"If timestamps for session start and end are included in the raw data collection, then these fields can be used as the cropping start and end points. If not, users must first determine the appropriate start and end points from whatever timestamps are relevant. For example, in the example analysis provided the session is cropped to 15 minutes before the first injection time stamp, and 60 minutes after the second injection time stamp. Code example of preparing the start and end indices:","title":"Index Preparation"},{"location":"userguide/plotdata/#function-cropfpdata","text":"REQUIRED INPUTS: data: Data structure created by the LoadKeyData function. Each session should be a separate row. The data structure must containing at least the fields specified in the additional inputs. whichcropstart: A string containing the name of the field with the locations of the session start indices. Everything before the start index will be cropped. whichcropend: A string containing the name of the field with the locations of the session end indices. Everything after the end index will be cropped. whichstreams: A cell array containing the field names of all the streams to be cropped. This should include both the signal and the background streams. OPTIONAL INPUTS: whichepocs: A cell array containing the field names of all the epochs (time stamps) to be adjusted. This input can contain as many inputs as the experimental paradigm requires, and each timestamp will be adjusted by subtracting the start index - 1. Code example of cropping: After data preparation is complete, move to Signal Processing .","title":"FUNCTION: cropFPdata"},{"location":"userguide/signalprocessing/","text":"Signal Processing After raw photometry data is loaded in to MATLAB, signal processing is conducted to account for photobleaching, motion artifacts, and other sources of \"noise\". The signal processing functions are written to be as flexible to differing streams and naming conventions as possible, but if the functions don't match your data, please reach out and let us know and we will update. Background Scaling, Subtraction, and Filtering To correct for photobleaching and motion artifact, the background is scaled to the signal stream and subtracted. While previous tools and packages have used regression based approaches, PASTa scales the background based on the frequency domain of the streams, preventing over or underfitting and maintaining the shape of the background. Background Scaling and Subtraction To determine the scaling factor for the background stream relative to the signal stream, both the signal and background streams are converted to the frequency domain via Fast Fourier Transform (FFT). The scaling factor is calculated as for all frequencies greater than 10 Hz. The background stream is scaled in the time domain; the background is centered around zero, multiplied by the scaling factor, and then adjusted to center around the signal mean. The scaled background is subtracted from the raw signal in the time domain. Subtracted signal is output as dF/F, where dF/F = (Signal - Scaled Background) / Scaled Background. If desired, users can override the default to output the as dF instead (dF = Signal - Scaled Background). Users have the ability to override PASTa protocol defaults to modify parameters including the scaling threshold frequency cutoff, subtracted data output, or select an alternative method of background scaling. Examples of Background Scaling and Subtraction with VTA GCaMP6f, NAcLS dLight1.3b, and NAcLS GRABDA2H Figure 2: Background scaling and subtraction examples for VTA GCaMP6f, NAcLS dLight1.3b, and NAcLS GRABDA2H. A) Traces of 465nm (signal) and 405nm (background) raw streams. B) Magnitude frequency plots of the Fast Fourier Transform (FFT) of raw, overlaid raw, and overlaid raw 465 and scaled 405nm streams. C) Trace of raw 465nm stream with overlaid scaled 405nm stream. D) Subtracted signal output as dF/F. Overall, frequency background scaling aligns the background with the signal, preventing over or under scaling while preserving the shape of both signal streams. Alternative Background Scaling Methods In our hands, frequency scaling performs better than other scaling approaches. Advantages are particularly notable for sensors such as GRABDA2H, for which 405nm is not a perfect isosbestic control. Use of frequency scaling rescues the use of the 405nm stream to control for photobleaching and motion artifact. This may be particularly useful as new sensors are continually in development, not all of which have an isosbestic or commercially available control wavelength for use in photometry systems. However, users may want to use or compare to other commonly used methods of scaling the background to the signal. The PASTa toolbox subtraction function includes options to use OLS regression, detrending and OLS regression, Lowess Smoothing and OLS Regression, and IRLS regression to scale the background prior to subtraction. Comparison of Scaling Methods with VTA GCaMP6f, NAcLS dLight1.3b, and NAcLS GRABDA2H Figure 3: Background scaling, subtraction examples and magnitude frequency plots for VTA GCaMP6f, NAcLS dLight1.3b, and NAcLS GRABDA2H with differing background scaling methods. A) Frequency Scaling: PASTa Protocol default method; The raw background is scaled to the signal based on a constant scaling factor determined by the ratio of the background to the signal in the frequency domain for frequencies greater than 10 Hz. B) OLS Regression Scaling: Commonly used method where the raw background is scaled to the signal with ordinary least squares regression, using the model fit to generate the scaled background stream. C) Linear Detrend and OLS Regression: Prior to scaling, both the raw signal and the raw background streams are detrended to remove the linear component of the stream (this is usually the decay of the signal over time). Ordinary least squares regression is then used with the detrended signals to generate the scaled background stream. D) Lowess Smoothing and OLS Regression: Prior to scaling, both the raw signal and the raw background streams are smoothed via Lowess smoothing. Ordinary least squares regression is then used with the smoothed signals to generate the scaled background stream. E) IRLS Regression: Relatively newer method where waw background is scaled to the signal with iteratively reweighted least squares regression to generate the scaled background stream. Figure 4: Samples of scaled background and subtracted signal across scaling methods and sensors. Overall, correlations indicate that while most methods are similar for GCaMP6f and dLight1.3b, for GRABDA2H frequency scaling preserves the shape of the background and prevents underscaling relative to other methods. Filtering After subtraction, the signal is filtered to remove high frequency noise and facilitate further analysis. The PASTa Protocol defaults to applying a 3rd order bandpass Butterworth filter with a high pass cutoff of 0.0051 Hz to remove the zero frequency DC component of the signal and a low pass cutoff of 2.286 Hz to remove high frequency components outside the typical band of interest for photometry sensors. Figure 5: Examples of subtracted and filtered data for for VTA GCaMP6f, NAcLS dLight1.3b, and NAcLS GRABDA2H. A) Magnitude frequency plots of the Fast Fourier Transform (FFT) of the subtracted and filtered streams. Note that the Butterworth bandpass filter is overlaid (grey dashed line) on the pre-filtering subtracted stream magnitude frequency plots. B) Trace of the subtracted stream (signal - scaled background). C) Trace of the subtracted and filtered stream. D) Zoomed in overlaid example of the subtracted and filtered streams. Note that the filtered stream is in the darker shade. While the PASTa Protocol has default filter settings, users can override these as required by sensor or experimental design to modify the filter type (band-pass, high-pass, low-pass), order, and cutoff frequencies. Function: subtractFPdata Subtracts the specified background channel from the specified signal channel and applies a Butterworth filter. Outputs data as dF/F (default) or dF. REQUIRED INPUTS: data: Data structure created by the LoadKeyData function. Each session should be a separate row. The data structure must containing at least the fields specified in the additional inputs. whichsigfield: A string with the name of the field containing the signal stream. For example, 'sig'. whichbaqfield: A string with the name of the field containing the signal stream. For example, 'baq'. whichfs: A string with the name of the field containing the sampling rate of the streams. For example, 'fs'. OPTIONAL INPUTS: baqscalingtype: A string that specifics the type of background scaling to apply. Default: 'frequency'. 'frequency': Scales the background to the signal channel based on ratio of specified frequency bands in the FFT of the channels 'sigmean': Scales the background to the signal channel based on the ratio of the mean of the signal to the mean of the background. 'OLS': Uses ordinary least-squares regression to generate scaled background. 'detrendedOLS': Removes the linear trend from signal and background streams prior to using ordinary least-squares regression to generate scaled background. 'smoothedOLS': Applies lowess smoothing to the signal and background streams prior to using ordinary least-squares regression to generate scaled background. 'IRLS': Uses iteratively reweighted least squares regression to generate scaled background. baqscalingfreq: Only used with 'frequency' baqscaling. An integer to specify the frequency (Hz) threshold for scaling the background to signal channel. Frequencies above this value will be included in the scaling factor determination. Default: 10 baqscalingperc: Only used with 'frequency' and 'sigmean' baqscaling. Adjusts the background scaling factor to be a percent of the derived scaling factor value. Input should be between 0 and 1. Default: 1 (100%) subtractionoutput: A string specifying the output type for the subtracted data. Default: 'dff' 'dff': Subtracted signal is output as delta F/F. dF/F = (Signal - Scaled Background) / Scaled Background 'df': Subtracted signal is output as delta F. dF = Signal - Scaled Background filtertype: A string that specifies the type of filter to be applied to the subtracted data stream. Default: 'bandpass' 'nofilter': No filter will be applied. 'bandpass': A bandpass filter will be applied. 'highpass': Only the high pass filter will be applied. 'lowpass': Only the low pass filter will be applied. padding: Set to 1 (default) to apply padding. Padding takes the specific percent of the start of the stream, flips it, and appends it to the data before filtering. Appended data is trimmed after filtration. The prevents issues that can occur with filtering the start of any data stream due to the incomplete initial window. Set to 0 to turn off padding. Default: 1 paddingperc: Percent of data length to use to determine the number of samples to be appended to the beginning and end of data in padding. Set to minimum 10%. Input should range from 0 to 1. Default: 0.1 (10%) filterorder: The order to be used for the Butterworth filter. Default: 3 highpasscutoff: The cutoff frequency (Hz) to be used for the high pass Butterworth filter. Default: 2.2860. lowpasscutoff: The cutoff frequency (Hz) to be used for the low pass Butterworth filter. Default: 0.0051. supressdisp: If set to anything other than 0, this will suppress the command window displays. Default: 0 OUTPUTS: data: The original data structure with added fields with the function inputs, scaled background (baq_scaled), subtracted signal (sigsub), and subtracted and filtered signal (sigfilt). Code example: Subtraction with default scaling and filter parameters Code example: Subtraction with background scaling type set to OLS Regression and filter type set to highpass only. Normalization Normalization converts the filtered signal to Z score. Multiple methods are included in the tool box to accomodate a variety of experimental designs. Whole session normalization uses the mean and SD of the whole session. Session baseline uses the mean and SD from a specified session baseline, which may be useful in cases where a drug is delivered mid session, experimental events occur mid session, or other treatments may result in a sustained shift that could bias signal normalization. Data can also be normalized on an individual trial basis to a local pre-trial baseline - see the Trial Analysis section of the user guide. Figure 5: Normalization examples. A) Normalization (Z Score) to whole session mean and SD. B) Normalization (Z Score) to a 3-min session baseline mean and SD. Function: normSession Normalizes the data stream to Z Score based on the whole session mean and SD. REQUIRED INPUTS: data: Data structure containing at least the stream to be normalized. Each session should be a separate row. whichstream: A string with the name of the field containing the stream to be normalized. For example, 'sigfilt'. OUTPUTS: data: The original data structure with the added fields 'data.WHICHSTREAMz_normsession' containing the whole session normalized stream. Code example: Function: normBaseline Normalizes the whole session data stream to Z Score based on a baseline period. REQUIRED INPUTS: data: Data structure containing at least the stream to be normalized, a field with the baseline start index, and a field with the baseline end index. Each session should be a separate row. whichstream: A string with the name of the field containing the stream to be normalized. For example, 'sigfilt'. whichblstart: A string with the name of the field containing the index of the start of the baseline period. This field must be prepared before using the normBaseline function. whichblend: A string with the name of the field containing the index of the end of the baseline period. This field must be prepared before using the normBaseline function. OUTPUTS: data: The original data structure with the added fields 'data.WHICHSTREAMz_normsession' containing the whole session normalized stream. Code example: Differing normalization methods may be advantageous depending on the experimental design. If additional options are required, please let us know!","title":"Signal Processing"},{"location":"userguide/signalprocessing/#signal-processing","text":"After raw photometry data is loaded in to MATLAB, signal processing is conducted to account for photobleaching, motion artifacts, and other sources of \"noise\". The signal processing functions are written to be as flexible to differing streams and naming conventions as possible, but if the functions don't match your data, please reach out and let us know and we will update.","title":"Signal Processing"},{"location":"userguide/signalprocessing/#background-scaling-subtraction-and-filtering","text":"To correct for photobleaching and motion artifact, the background is scaled to the signal stream and subtracted. While previous tools and packages have used regression based approaches, PASTa scales the background based on the frequency domain of the streams, preventing over or underfitting and maintaining the shape of the background.","title":"Background Scaling, Subtraction, and Filtering"},{"location":"userguide/signalprocessing/#background-scaling-and-subtraction","text":"To determine the scaling factor for the background stream relative to the signal stream, both the signal and background streams are converted to the frequency domain via Fast Fourier Transform (FFT). The scaling factor is calculated as for all frequencies greater than 10 Hz. The background stream is scaled in the time domain; the background is centered around zero, multiplied by the scaling factor, and then adjusted to center around the signal mean. The scaled background is subtracted from the raw signal in the time domain. Subtracted signal is output as dF/F, where dF/F = (Signal - Scaled Background) / Scaled Background. If desired, users can override the default to output the as dF instead (dF = Signal - Scaled Background). Users have the ability to override PASTa protocol defaults to modify parameters including the scaling threshold frequency cutoff, subtracted data output, or select an alternative method of background scaling.","title":"Background Scaling and Subtraction"},{"location":"userguide/signalprocessing/#examples-of-background-scaling-and-subtraction-with-vta-gcamp6f-nacls-dlight13b-and-nacls-grabda2h","text":"Figure 2: Background scaling and subtraction examples for VTA GCaMP6f, NAcLS dLight1.3b, and NAcLS GRABDA2H. A) Traces of 465nm (signal) and 405nm (background) raw streams. B) Magnitude frequency plots of the Fast Fourier Transform (FFT) of raw, overlaid raw, and overlaid raw 465 and scaled 405nm streams. C) Trace of raw 465nm stream with overlaid scaled 405nm stream. D) Subtracted signal output as dF/F. Overall, frequency background scaling aligns the background with the signal, preventing over or under scaling while preserving the shape of both signal streams.","title":"Examples of Background Scaling and Subtraction with VTA GCaMP6f, NAcLS dLight1.3b, and NAcLS GRABDA2H"},{"location":"userguide/signalprocessing/#alternative-background-scaling-methods","text":"In our hands, frequency scaling performs better than other scaling approaches. Advantages are particularly notable for sensors such as GRABDA2H, for which 405nm is not a perfect isosbestic control. Use of frequency scaling rescues the use of the 405nm stream to control for photobleaching and motion artifact. This may be particularly useful as new sensors are continually in development, not all of which have an isosbestic or commercially available control wavelength for use in photometry systems. However, users may want to use or compare to other commonly used methods of scaling the background to the signal. The PASTa toolbox subtraction function includes options to use OLS regression, detrending and OLS regression, Lowess Smoothing and OLS Regression, and IRLS regression to scale the background prior to subtraction.","title":"Alternative Background Scaling Methods"},{"location":"userguide/signalprocessing/#comparison-of-scaling-methods-with-vta-gcamp6f-nacls-dlight13b-and-nacls-grabda2h","text":"Figure 3: Background scaling, subtraction examples and magnitude frequency plots for VTA GCaMP6f, NAcLS dLight1.3b, and NAcLS GRABDA2H with differing background scaling methods. A) Frequency Scaling: PASTa Protocol default method; The raw background is scaled to the signal based on a constant scaling factor determined by the ratio of the background to the signal in the frequency domain for frequencies greater than 10 Hz. B) OLS Regression Scaling: Commonly used method where the raw background is scaled to the signal with ordinary least squares regression, using the model fit to generate the scaled background stream. C) Linear Detrend and OLS Regression: Prior to scaling, both the raw signal and the raw background streams are detrended to remove the linear component of the stream (this is usually the decay of the signal over time). Ordinary least squares regression is then used with the detrended signals to generate the scaled background stream. D) Lowess Smoothing and OLS Regression: Prior to scaling, both the raw signal and the raw background streams are smoothed via Lowess smoothing. Ordinary least squares regression is then used with the smoothed signals to generate the scaled background stream. E) IRLS Regression: Relatively newer method where waw background is scaled to the signal with iteratively reweighted least squares regression to generate the scaled background stream. Figure 4: Samples of scaled background and subtracted signal across scaling methods and sensors. Overall, correlations indicate that while most methods are similar for GCaMP6f and dLight1.3b, for GRABDA2H frequency scaling preserves the shape of the background and prevents underscaling relative to other methods.","title":"Comparison of Scaling Methods with VTA GCaMP6f, NAcLS dLight1.3b, and NAcLS GRABDA2H"},{"location":"userguide/signalprocessing/#filtering","text":"After subtraction, the signal is filtered to remove high frequency noise and facilitate further analysis. The PASTa Protocol defaults to applying a 3rd order bandpass Butterworth filter with a high pass cutoff of 0.0051 Hz to remove the zero frequency DC component of the signal and a low pass cutoff of 2.286 Hz to remove high frequency components outside the typical band of interest for photometry sensors. Figure 5: Examples of subtracted and filtered data for for VTA GCaMP6f, NAcLS dLight1.3b, and NAcLS GRABDA2H. A) Magnitude frequency plots of the Fast Fourier Transform (FFT) of the subtracted and filtered streams. Note that the Butterworth bandpass filter is overlaid (grey dashed line) on the pre-filtering subtracted stream magnitude frequency plots. B) Trace of the subtracted stream (signal - scaled background). C) Trace of the subtracted and filtered stream. D) Zoomed in overlaid example of the subtracted and filtered streams. Note that the filtered stream is in the darker shade. While the PASTa Protocol has default filter settings, users can override these as required by sensor or experimental design to modify the filter type (band-pass, high-pass, low-pass), order, and cutoff frequencies.","title":"Filtering"},{"location":"userguide/signalprocessing/#function-subtractfpdata","text":"Subtracts the specified background channel from the specified signal channel and applies a Butterworth filter. Outputs data as dF/F (default) or dF. REQUIRED INPUTS: data: Data structure created by the LoadKeyData function. Each session should be a separate row. The data structure must containing at least the fields specified in the additional inputs. whichsigfield: A string with the name of the field containing the signal stream. For example, 'sig'. whichbaqfield: A string with the name of the field containing the signal stream. For example, 'baq'. whichfs: A string with the name of the field containing the sampling rate of the streams. For example, 'fs'. OPTIONAL INPUTS: baqscalingtype: A string that specifics the type of background scaling to apply. Default: 'frequency'. 'frequency': Scales the background to the signal channel based on ratio of specified frequency bands in the FFT of the channels 'sigmean': Scales the background to the signal channel based on the ratio of the mean of the signal to the mean of the background. 'OLS': Uses ordinary least-squares regression to generate scaled background. 'detrendedOLS': Removes the linear trend from signal and background streams prior to using ordinary least-squares regression to generate scaled background. 'smoothedOLS': Applies lowess smoothing to the signal and background streams prior to using ordinary least-squares regression to generate scaled background. 'IRLS': Uses iteratively reweighted least squares regression to generate scaled background. baqscalingfreq: Only used with 'frequency' baqscaling. An integer to specify the frequency (Hz) threshold for scaling the background to signal channel. Frequencies above this value will be included in the scaling factor determination. Default: 10 baqscalingperc: Only used with 'frequency' and 'sigmean' baqscaling. Adjusts the background scaling factor to be a percent of the derived scaling factor value. Input should be between 0 and 1. Default: 1 (100%) subtractionoutput: A string specifying the output type for the subtracted data. Default: 'dff' 'dff': Subtracted signal is output as delta F/F. dF/F = (Signal - Scaled Background) / Scaled Background 'df': Subtracted signal is output as delta F. dF = Signal - Scaled Background filtertype: A string that specifies the type of filter to be applied to the subtracted data stream. Default: 'bandpass' 'nofilter': No filter will be applied. 'bandpass': A bandpass filter will be applied. 'highpass': Only the high pass filter will be applied. 'lowpass': Only the low pass filter will be applied. padding: Set to 1 (default) to apply padding. Padding takes the specific percent of the start of the stream, flips it, and appends it to the data before filtering. Appended data is trimmed after filtration. The prevents issues that can occur with filtering the start of any data stream due to the incomplete initial window. Set to 0 to turn off padding. Default: 1 paddingperc: Percent of data length to use to determine the number of samples to be appended to the beginning and end of data in padding. Set to minimum 10%. Input should range from 0 to 1. Default: 0.1 (10%) filterorder: The order to be used for the Butterworth filter. Default: 3 highpasscutoff: The cutoff frequency (Hz) to be used for the high pass Butterworth filter. Default: 2.2860. lowpasscutoff: The cutoff frequency (Hz) to be used for the low pass Butterworth filter. Default: 0.0051. supressdisp: If set to anything other than 0, this will suppress the command window displays. Default: 0 OUTPUTS: data: The original data structure with added fields with the function inputs, scaled background (baq_scaled), subtracted signal (sigsub), and subtracted and filtered signal (sigfilt). Code example: Subtraction with default scaling and filter parameters Code example: Subtraction with background scaling type set to OLS Regression and filter type set to highpass only.","title":"Function: subtractFPdata"},{"location":"userguide/signalprocessing/#normalization","text":"Normalization converts the filtered signal to Z score. Multiple methods are included in the tool box to accomodate a variety of experimental designs. Whole session normalization uses the mean and SD of the whole session. Session baseline uses the mean and SD from a specified session baseline, which may be useful in cases where a drug is delivered mid session, experimental events occur mid session, or other treatments may result in a sustained shift that could bias signal normalization. Data can also be normalized on an individual trial basis to a local pre-trial baseline - see the Trial Analysis section of the user guide. Figure 5: Normalization examples. A) Normalization (Z Score) to whole session mean and SD. B) Normalization (Z Score) to a 3-min session baseline mean and SD.","title":"Normalization"},{"location":"userguide/signalprocessing/#function-normsession","text":"Normalizes the data stream to Z Score based on the whole session mean and SD. REQUIRED INPUTS: data: Data structure containing at least the stream to be normalized. Each session should be a separate row. whichstream: A string with the name of the field containing the stream to be normalized. For example, 'sigfilt'. OUTPUTS: data: The original data structure with the added fields 'data.WHICHSTREAMz_normsession' containing the whole session normalized stream. Code example:","title":"Function: normSession"},{"location":"userguide/signalprocessing/#function-normbaseline","text":"Normalizes the whole session data stream to Z Score based on a baseline period. REQUIRED INPUTS: data: Data structure containing at least the stream to be normalized, a field with the baseline start index, and a field with the baseline end index. Each session should be a separate row. whichstream: A string with the name of the field containing the stream to be normalized. For example, 'sigfilt'. whichblstart: A string with the name of the field containing the index of the start of the baseline period. This field must be prepared before using the normBaseline function. whichblend: A string with the name of the field containing the index of the end of the baseline period. This field must be prepared before using the normBaseline function. OUTPUTS: data: The original data structure with the added fields 'data.WHICHSTREAMz_normsession' containing the whole session normalized stream. Code example: Differing normalization methods may be advantageous depending on the experimental design. If additional options are required, please let us know!","title":"Function: normBaseline"},{"location":"userguide/transientanalysis/","text":"Transient Detection and Quantification Transient detection is a critical component of fiber photometry analyses, identifying relevant increases in sensor activation. Previous tools and packages have used a sliding window approach, where all values above an absolute threshold are counted as peaks. Here, we present a novel method of peak detection where each peak is compared to a local baseline and amplitude is calculated and compared to a threshold to determine inclusion. This allows for consistent parameters across the session and reliable detection of individual events despite signal absolute value fluctuation. Transient Event Detection Transients are detected as peaks with a greater amplitude than the specified threshold. To determine amplitude, first a pre-peak baseline must be identified. PASTa includes three options: window minimum (minimum value within user defined pre-peak window size, e.g. 800ms), window mean (mean of user defined pre-peak window), or local min (absolute local minimum preceding the peak). The amplitude threshold is set by the user, and recommended to be 3SDs. If data are normalized in Z scores, then the criterion is an increase of 3 from baseline. If not, the user inputs the actual value that corresponds to 3SDs in the data stream. Prepare Thresholds Prior to detecting session transients, users must prepare the thresholds to be used for event detection. Transients are detected as peaks with a greater amplitude than the specified threshold. The amplitude threshold is set by the user, and recommended to be 3SDs. If data are normalized in Z scores, then the criterion is an increase of 3 from baseline. If not, the user inputs the actual value that corresponds to 3SDs in the data stream. Users must add the thresholds to each row of the data structure prior to moving on. Code example: Preparation of 'threshold3SD' field in data structure containing the value 3 for each row of data. Thresholds are set to the numeric value 3 because transients will be identified in Z scored data streams. Function: findSessionTransients Finds transients for the whole session. Pre-transient baselines can be determine as pre-peak baseline window minimum, pre-peak baseline window mean, or local minimum preceding the peak within the baseline window. NOTE: The findSessionTransients function sets default values for optional input parameters and then calls subfunctions for each type of peak baseline. Note that if you'd prefer to directly call the sub-function desired, all inputs are required and defaults are not specified. REQUIRED INPUTS: data: This is a structure that contains at least the data stream you want to analyze for transient events. whichbltype: A string specifying the the type of pre-transient baseline to use for transient amplitude determination and inclusion,and event quantification. Default: 'blmin' 'blmin': Pre-transient baselines are set to the minimum value within the pre-transient window. 'blmean': Pre-transient baselines are set to the mean of the pre-transient window. 'localmin': Pre-transient baselines are set to the local minimum directly preceding the transient within the baseline window. whichstream: A string with the name of the field containing the stream to be analyzed for transients. For example, 'sigz_normsession'. whichthreshold: A variable containing a string with the name of the field containing the prepared numeric threshold values for each stream. For example, 'threshold_3SD'. whichfs: A string with the name of the field containing the sampling rate of the streams. For example, 'fs'. OPTIONAL INPUTS: preminstartms: Number of millseconds pre-transient to use as the start of the baseline window. Default: 1000 preminendms: Number of millseconds pre-transient to use as the end of the baseline window. Default: 100 posttransientms: Number of millseconds post-transient to use for the post peak baseline and trimmed data output. Default: 2000 quantificationheight: The height at which to characterize rise time, fall time, peak width, and AUC. Must be a number between 0 and 1. Default: 0.5 outputtransientdata: Set to 1 to output cut data streams for each transient event. Set to 0 to skip. Default: 1 OUTPUTS: data: The original data structure with sessiontransients_WHICHBLTYPE_THRESHOLDLABEL added in. The output contains four nested tables: inputs: Includes all required and optional function inputs. If optional inputs are not specified, defaults will be applied. transientquantification: Includes the quantified variables for each transient, including amplitude, rise time, fall time, width, and AUC. See Transient Quantification section below for addition details on quantification outputs. transientstreamlocs: Pre-transient baseline, transient peak, rise, and fall locations for each transient to match the cut transient stream data. transientstreamdata: Cut data stream from baseline start to the end of the post-transient period for each transient event. NOTE: For all data outputs, each transient is in a separate row. If OUTPUTTRANSIENTDATA is set to anything other than 1, the TRANSIENTSTREAMLOCS and TRANSIENTSTREAMDATA tables will be skipped and not included in the output. Code example: Whole session transient detection with baseline minimum and default inputs. Code example: Whole session transient detection with baseline mean and shortened pre-peak baseline window. Code example: Whole session transient detection with local minimum and 25% quantification height. Transient Event Quantification Multiple features of transient events can be quantitatively analyzed and compared. Peak detection functions automatically calculate numerous variables for each transient to characterize aspects of both event rise and fall. Frequency: Characterized as peaks per minute. Frequency can be analyzed as whole session frequency, or peaks can be divided into time bins or experimental phases (ITI, during trial, etc). Amplitude: The height of the event from the pre-peak baseline to the max peak. Note that all events will be at least the value of the set threshold (default 3SD). Rise and Fall Time: Transient rise and fall are measured by default from half height to peak and output in samples and ms. This allows for analysis of separate rise and fall dynamic shifts. The quantification height to be measured from can be manually adjusted if desired. Width: Transient width is measured as the width from the pre-peak quantification height (defaults to half height) location to the post-peak quantification height location. This is equivalent to the rise plus the fall. AUC: Total area under the curve from half height to peak, calculated via the trapezoidal method. Prior to AUC calculation, each transient is linearly transformed so pre-peak baseline is equal to zero. If the height to be measured from is adjusted for rise and fall time, it will also be adjusted for AUC. Figure 6: Transient example with labeled detection parameters and output variables. After detection and quatification of individual transients, PASTa includes flexible functions to group transients in the most experimentally relevant manner, such as by time window and experimental condition. It may be relevant to identify how the frequency or other features of transients change over the course of the session. One way to determine within session changes is to divide the session into time bins. We typically use 3-5 minute bins, but bin length may vary depending on the treatment, session length, sensor, and region being recorded. See the function binSessionTransients below for more detail on how transients are assigned to bins. Function Outputs: findSessionTransients findSessionTransients adds numerous transient quantification values to the data structure for easy output and flexible analysis. VARIABLES: transientID: Unique integer ID for each transient identified. IDs start at 1. maxloc: Stream index of the maximum transient peak value. maxval: Maximum transient peak value. preminstartloc: Stream index of the start of the pre-peak baseline window. preminendloc: Stream index of the end of the pre-peak baseline window. preminloc: Only included in 'blmin' and 'localmin' outputs. Stream index of the actual pre-peak baseline. preminval: Value of the pre-peak baseline. For 'blmin' and 'localmin', this will be the actual value. For 'blmean', this will be the mean of the baseline window. amp: Amplitude of the transient (maxval - preminval). risestartloc: Stream index of the start of the rise period of the transient, determined by the quantification height. This value is identified as the sample before the peak closest to the preminval + (amp * quantification height). risestartval: Value of the start of the rise period of the transient. risesamples: Length of the transient event rise period in samples. This is calculated as the maxloc - risestartloc. risems: Duration of the transient event rise period in ms. fallendloc: Stream index of the end of the fall period of the transient, determined by the quantification height. This value is identified as the sample after the peak closest to the maxval - (amp * quantification height). fallendval: Value of the end of the fall period of the transient. fallsamples: Length of the transient event fall period in samples. This is calculated as the fallendloc - maxloc. fallms: Duration of the transient event fall period in ms. widthsamples: Total width of the rise and fall of the transient event. Number of samples from the rise start to the fall end locations. widthms: Total duration of the rise and fall of the transient event in ms. AUC: Area under the curve from the quantification height to the transient peak. Calculated via the trapezoidal method. Output Example - Adding Transients to the Data Structure: Output of findSessionTransients, which is a sub-structure under the field sessiontransients added to the main data structure. Output Example - Function Inputs: Inputs passed to the findSessionTransients functions are output to the table Inputs within the sessiontransients field of the main data structure. Output Example - Transient Quantification: Quantification of individual transient events is output to the table transientquantification within the sessiontransients field of the main data structure. Each transient is in a separate row with a unique transient ID. Output Example - Individual Transient Trace Indexes: For individual transient traces, transient stream locations of peak and baseline indexes and values are added to the table transientstreamlocs . Each transient is in a separate row. Output Example - Individual Transient Traces: Actual stream values for individual transient traces, which are cut from the start of the baseline window to the end of the post peak period, and output to the table transientstreamdata . Each transient is in a separate row, and traces are spatially aligned consistently with the transientstreamlocs for easy plotting and analysis. Function: binSessionTransients Adds the variable 'Bin' to the transient quantification table and assigns each transient a bin based on it's location within the session. The length for each bin defaults to 5 minutes. By default, the function will calculate the number of bins for each session by dividing the total session length by the length of each bin. Users can manually override this calculation and specify the exact number of bins if desired. REQUIRED INPUTS: data: his is a structure that contains at least the field containing the stream from which transients were detected, the sampling rate, and the fields containing the transient data with a column of transient max indexes. whichstream: A string with the name of the field containing the data stream input to the findSessionTransients to identify transients from. This is used to determine how many bins are necessary. For example, 'sigz_normsession' whichfs: A string with the name of the field containing the sampling rate of the streams. For example, 'fs'. whichtransients: A string with the name of the parent field containing the table of transients that you want to identify bins for. For example, 'sessiontransients_blmin_3SD'. OPTIONAL INPUTS: whichtransientstable: The name of the field within WHICHTRANSIENTS that contains the quantification of individual transient events. This input only needs to be specified if not using the format output from the FINDSESSIONTRANSIENTS functions. Default: 'transientquantification'. whichmaxlocs: A string with the name of the field containing the transient max locations (indexes) relative to the whole session. This input only needs to be specified if not using the format output from the FINDSESSIONTRANSIENTS functions. Default: 'maxloc' binlengthmins: Bin length in number of minutes. Default: 5 nbinsoverride: Manual override to set the number of bins. If set to anything other than 0, users can override the stream-length based calculation of the number of bins per session and set their own number. Default: 0 OUTPUTS: data: This is the original data structure with bins added to the specified table of transients. The bin column will be labeled 'Bin_BINLENGTHMINS' Code Example: Binning individual transients into 5 minute bins. Output Example: Individual transients with Bin assignment.Each transient is in a separate row. Comparison of Transient Events with VTA GCaMP6f, NAcLS dLight1.3b, and NAcLS GRABDA2H To validate our approach to transient detection, we analyzed identified transient events in dopamine recordings via three sensors: VTA GCaMP6f, NAcLS dLight1.3b, and NAcLS GRABDA2H. Figure 7: Transient detection and quantification examples for A) GCaMP6f, B) dLight1.3b, and C) GRABDA2H. Transients were detected with a threshold of 3SD and an 800ms window minimum pre-peak baseline. Bar plots of group means by sensor for D) average whole session peak frequency, E) mean peak amplitude, F) total peak rise time from pre-peak baseline to peak, G) rise time from half height to peak, H) fall time from peak to half height, and I) half height AUC. Overall, individual sensor results align well with published kinetics. Exporting Transient Events To further analyze changes in transient events, users may want to export the transient quantification results to a csv file to be processed, analyzed, and graphed in other programs such as R Studio. To do so, users can easily generate a csv file with every transient event for all sessions in the data structure. Function: exportSessionTransients Creates a table of all transient events for all sessions and saves it to a csv table for easy import to other analysis programs or platforms. Note that this function can also be called to create the table and output to a table in the MATLAB workspace as well. REQUIRED INPUTS: data: This is a structure that contains at least the output from the function findSessionTransients . whichtransients: The name of the parent field containing the table of transients that you want to export. For example, 'sessiontransients_blmin_3SD'. exportfilepath: Path to the folder location where the created table should be saved to. Note that this path must end in a forward slash or the save function will not work. addvariables: A cell array containing any additional variables from the data structure to be added to the transients table. Variables will be added to every row of the output structure. Cell array inputs must be the names of fields in the data structure. At a minimum, this should contain the subject ID. If multiple sessions per subject are included in the data structure, make sure a session ID variable is also included. OPTIONAL INPUTS: whichtransientstable: The name of the field within WHICHTRANSIENTS that contains the quantification of individual transient events. This input only needs to be specified if not using the format output from the FINDSESSIONTRANSIENTS functions. Default: 'transientquantification'. OUTPUTS: This function outputs a csv file with all transients for all sessions in the data structure. The file will be output at the specified file path. Variables contained in addvariables will be moved to the first columns of the file for easy identification. OPTIONAL - alltransients: If the function is called into an object, the table ALLTRANSIENTS will also be saved to an object in the MATLAB workspace. If users prefer to analyze group or session means/differences in MATLAB, this option should be used. NOTE: In the exported csv file and output table, each transient is in a separate row. ID variables such as Subject or Session IDs will be added to the first few columns of every transient row. Code Example: Exporting all transients for each session into one table with added ID variables for Subject, Treatment Number, and Injection Type.","title":"Transient Analysis"},{"location":"userguide/transientanalysis/#transient-detection-and-quantification","text":"Transient detection is a critical component of fiber photometry analyses, identifying relevant increases in sensor activation. Previous tools and packages have used a sliding window approach, where all values above an absolute threshold are counted as peaks. Here, we present a novel method of peak detection where each peak is compared to a local baseline and amplitude is calculated and compared to a threshold to determine inclusion. This allows for consistent parameters across the session and reliable detection of individual events despite signal absolute value fluctuation.","title":"Transient Detection and Quantification"},{"location":"userguide/transientanalysis/#transient-event-detection","text":"Transients are detected as peaks with a greater amplitude than the specified threshold. To determine amplitude, first a pre-peak baseline must be identified. PASTa includes three options: window minimum (minimum value within user defined pre-peak window size, e.g. 800ms), window mean (mean of user defined pre-peak window), or local min (absolute local minimum preceding the peak). The amplitude threshold is set by the user, and recommended to be 3SDs. If data are normalized in Z scores, then the criterion is an increase of 3 from baseline. If not, the user inputs the actual value that corresponds to 3SDs in the data stream.","title":"Transient Event Detection"},{"location":"userguide/transientanalysis/#prepare-thresholds","text":"Prior to detecting session transients, users must prepare the thresholds to be used for event detection. Transients are detected as peaks with a greater amplitude than the specified threshold. The amplitude threshold is set by the user, and recommended to be 3SDs. If data are normalized in Z scores, then the criterion is an increase of 3 from baseline. If not, the user inputs the actual value that corresponds to 3SDs in the data stream. Users must add the thresholds to each row of the data structure prior to moving on. Code example: Preparation of 'threshold3SD' field in data structure containing the value 3 for each row of data. Thresholds are set to the numeric value 3 because transients will be identified in Z scored data streams.","title":"Prepare Thresholds"},{"location":"userguide/transientanalysis/#function-findsessiontransients","text":"Finds transients for the whole session. Pre-transient baselines can be determine as pre-peak baseline window minimum, pre-peak baseline window mean, or local minimum preceding the peak within the baseline window. NOTE: The findSessionTransients function sets default values for optional input parameters and then calls subfunctions for each type of peak baseline. Note that if you'd prefer to directly call the sub-function desired, all inputs are required and defaults are not specified. REQUIRED INPUTS: data: This is a structure that contains at least the data stream you want to analyze for transient events. whichbltype: A string specifying the the type of pre-transient baseline to use for transient amplitude determination and inclusion,and event quantification. Default: 'blmin' 'blmin': Pre-transient baselines are set to the minimum value within the pre-transient window. 'blmean': Pre-transient baselines are set to the mean of the pre-transient window. 'localmin': Pre-transient baselines are set to the local minimum directly preceding the transient within the baseline window. whichstream: A string with the name of the field containing the stream to be analyzed for transients. For example, 'sigz_normsession'. whichthreshold: A variable containing a string with the name of the field containing the prepared numeric threshold values for each stream. For example, 'threshold_3SD'. whichfs: A string with the name of the field containing the sampling rate of the streams. For example, 'fs'. OPTIONAL INPUTS: preminstartms: Number of millseconds pre-transient to use as the start of the baseline window. Default: 1000 preminendms: Number of millseconds pre-transient to use as the end of the baseline window. Default: 100 posttransientms: Number of millseconds post-transient to use for the post peak baseline and trimmed data output. Default: 2000 quantificationheight: The height at which to characterize rise time, fall time, peak width, and AUC. Must be a number between 0 and 1. Default: 0.5 outputtransientdata: Set to 1 to output cut data streams for each transient event. Set to 0 to skip. Default: 1 OUTPUTS: data: The original data structure with sessiontransients_WHICHBLTYPE_THRESHOLDLABEL added in. The output contains four nested tables: inputs: Includes all required and optional function inputs. If optional inputs are not specified, defaults will be applied. transientquantification: Includes the quantified variables for each transient, including amplitude, rise time, fall time, width, and AUC. See Transient Quantification section below for addition details on quantification outputs. transientstreamlocs: Pre-transient baseline, transient peak, rise, and fall locations for each transient to match the cut transient stream data. transientstreamdata: Cut data stream from baseline start to the end of the post-transient period for each transient event. NOTE: For all data outputs, each transient is in a separate row. If OUTPUTTRANSIENTDATA is set to anything other than 1, the TRANSIENTSTREAMLOCS and TRANSIENTSTREAMDATA tables will be skipped and not included in the output. Code example: Whole session transient detection with baseline minimum and default inputs. Code example: Whole session transient detection with baseline mean and shortened pre-peak baseline window. Code example: Whole session transient detection with local minimum and 25% quantification height.","title":"Function: findSessionTransients"},{"location":"userguide/transientanalysis/#transient-event-quantification","text":"Multiple features of transient events can be quantitatively analyzed and compared. Peak detection functions automatically calculate numerous variables for each transient to characterize aspects of both event rise and fall. Frequency: Characterized as peaks per minute. Frequency can be analyzed as whole session frequency, or peaks can be divided into time bins or experimental phases (ITI, during trial, etc). Amplitude: The height of the event from the pre-peak baseline to the max peak. Note that all events will be at least the value of the set threshold (default 3SD). Rise and Fall Time: Transient rise and fall are measured by default from half height to peak and output in samples and ms. This allows for analysis of separate rise and fall dynamic shifts. The quantification height to be measured from can be manually adjusted if desired. Width: Transient width is measured as the width from the pre-peak quantification height (defaults to half height) location to the post-peak quantification height location. This is equivalent to the rise plus the fall. AUC: Total area under the curve from half height to peak, calculated via the trapezoidal method. Prior to AUC calculation, each transient is linearly transformed so pre-peak baseline is equal to zero. If the height to be measured from is adjusted for rise and fall time, it will also be adjusted for AUC. Figure 6: Transient example with labeled detection parameters and output variables. After detection and quatification of individual transients, PASTa includes flexible functions to group transients in the most experimentally relevant manner, such as by time window and experimental condition. It may be relevant to identify how the frequency or other features of transients change over the course of the session. One way to determine within session changes is to divide the session into time bins. We typically use 3-5 minute bins, but bin length may vary depending on the treatment, session length, sensor, and region being recorded. See the function binSessionTransients below for more detail on how transients are assigned to bins.","title":"Transient Event Quantification"},{"location":"userguide/transientanalysis/#function-outputs-findsessiontransients","text":"findSessionTransients adds numerous transient quantification values to the data structure for easy output and flexible analysis. VARIABLES: transientID: Unique integer ID for each transient identified. IDs start at 1. maxloc: Stream index of the maximum transient peak value. maxval: Maximum transient peak value. preminstartloc: Stream index of the start of the pre-peak baseline window. preminendloc: Stream index of the end of the pre-peak baseline window. preminloc: Only included in 'blmin' and 'localmin' outputs. Stream index of the actual pre-peak baseline. preminval: Value of the pre-peak baseline. For 'blmin' and 'localmin', this will be the actual value. For 'blmean', this will be the mean of the baseline window. amp: Amplitude of the transient (maxval - preminval). risestartloc: Stream index of the start of the rise period of the transient, determined by the quantification height. This value is identified as the sample before the peak closest to the preminval + (amp * quantification height). risestartval: Value of the start of the rise period of the transient. risesamples: Length of the transient event rise period in samples. This is calculated as the maxloc - risestartloc. risems: Duration of the transient event rise period in ms. fallendloc: Stream index of the end of the fall period of the transient, determined by the quantification height. This value is identified as the sample after the peak closest to the maxval - (amp * quantification height). fallendval: Value of the end of the fall period of the transient. fallsamples: Length of the transient event fall period in samples. This is calculated as the fallendloc - maxloc. fallms: Duration of the transient event fall period in ms. widthsamples: Total width of the rise and fall of the transient event. Number of samples from the rise start to the fall end locations. widthms: Total duration of the rise and fall of the transient event in ms. AUC: Area under the curve from the quantification height to the transient peak. Calculated via the trapezoidal method. Output Example - Adding Transients to the Data Structure: Output of findSessionTransients, which is a sub-structure under the field sessiontransients added to the main data structure. Output Example - Function Inputs: Inputs passed to the findSessionTransients functions are output to the table Inputs within the sessiontransients field of the main data structure. Output Example - Transient Quantification: Quantification of individual transient events is output to the table transientquantification within the sessiontransients field of the main data structure. Each transient is in a separate row with a unique transient ID. Output Example - Individual Transient Trace Indexes: For individual transient traces, transient stream locations of peak and baseline indexes and values are added to the table transientstreamlocs . Each transient is in a separate row. Output Example - Individual Transient Traces: Actual stream values for individual transient traces, which are cut from the start of the baseline window to the end of the post peak period, and output to the table transientstreamdata . Each transient is in a separate row, and traces are spatially aligned consistently with the transientstreamlocs for easy plotting and analysis.","title":"Function Outputs: findSessionTransients"},{"location":"userguide/transientanalysis/#function-binsessiontransients","text":"Adds the variable 'Bin' to the transient quantification table and assigns each transient a bin based on it's location within the session. The length for each bin defaults to 5 minutes. By default, the function will calculate the number of bins for each session by dividing the total session length by the length of each bin. Users can manually override this calculation and specify the exact number of bins if desired. REQUIRED INPUTS: data: his is a structure that contains at least the field containing the stream from which transients were detected, the sampling rate, and the fields containing the transient data with a column of transient max indexes. whichstream: A string with the name of the field containing the data stream input to the findSessionTransients to identify transients from. This is used to determine how many bins are necessary. For example, 'sigz_normsession' whichfs: A string with the name of the field containing the sampling rate of the streams. For example, 'fs'. whichtransients: A string with the name of the parent field containing the table of transients that you want to identify bins for. For example, 'sessiontransients_blmin_3SD'. OPTIONAL INPUTS: whichtransientstable: The name of the field within WHICHTRANSIENTS that contains the quantification of individual transient events. This input only needs to be specified if not using the format output from the FINDSESSIONTRANSIENTS functions. Default: 'transientquantification'. whichmaxlocs: A string with the name of the field containing the transient max locations (indexes) relative to the whole session. This input only needs to be specified if not using the format output from the FINDSESSIONTRANSIENTS functions. Default: 'maxloc' binlengthmins: Bin length in number of minutes. Default: 5 nbinsoverride: Manual override to set the number of bins. If set to anything other than 0, users can override the stream-length based calculation of the number of bins per session and set their own number. Default: 0 OUTPUTS: data: This is the original data structure with bins added to the specified table of transients. The bin column will be labeled 'Bin_BINLENGTHMINS' Code Example: Binning individual transients into 5 minute bins. Output Example: Individual transients with Bin assignment.Each transient is in a separate row.","title":"Function: binSessionTransients"},{"location":"userguide/transientanalysis/#comparison-of-transient-events-with-vta-gcamp6f-nacls-dlight13b-and-nacls-grabda2h","text":"To validate our approach to transient detection, we analyzed identified transient events in dopamine recordings via three sensors: VTA GCaMP6f, NAcLS dLight1.3b, and NAcLS GRABDA2H. Figure 7: Transient detection and quantification examples for A) GCaMP6f, B) dLight1.3b, and C) GRABDA2H. Transients were detected with a threshold of 3SD and an 800ms window minimum pre-peak baseline. Bar plots of group means by sensor for D) average whole session peak frequency, E) mean peak amplitude, F) total peak rise time from pre-peak baseline to peak, G) rise time from half height to peak, H) fall time from peak to half height, and I) half height AUC. Overall, individual sensor results align well with published kinetics.","title":"Comparison of Transient Events with VTA GCaMP6f, NAcLS dLight1.3b, and NAcLS GRABDA2H"},{"location":"userguide/transientanalysis/#exporting-transient-events","text":"To further analyze changes in transient events, users may want to export the transient quantification results to a csv file to be processed, analyzed, and graphed in other programs such as R Studio. To do so, users can easily generate a csv file with every transient event for all sessions in the data structure.","title":"Exporting Transient Events"},{"location":"userguide/transientanalysis/#function-exportsessiontransients","text":"Creates a table of all transient events for all sessions and saves it to a csv table for easy import to other analysis programs or platforms. Note that this function can also be called to create the table and output to a table in the MATLAB workspace as well. REQUIRED INPUTS: data: This is a structure that contains at least the output from the function findSessionTransients . whichtransients: The name of the parent field containing the table of transients that you want to export. For example, 'sessiontransients_blmin_3SD'. exportfilepath: Path to the folder location where the created table should be saved to. Note that this path must end in a forward slash or the save function will not work. addvariables: A cell array containing any additional variables from the data structure to be added to the transients table. Variables will be added to every row of the output structure. Cell array inputs must be the names of fields in the data structure. At a minimum, this should contain the subject ID. If multiple sessions per subject are included in the data structure, make sure a session ID variable is also included. OPTIONAL INPUTS: whichtransientstable: The name of the field within WHICHTRANSIENTS that contains the quantification of individual transient events. This input only needs to be specified if not using the format output from the FINDSESSIONTRANSIENTS functions. Default: 'transientquantification'. OUTPUTS: This function outputs a csv file with all transients for all sessions in the data structure. The file will be output at the specified file path. Variables contained in addvariables will be moved to the first columns of the file for easy identification. OPTIONAL - alltransients: If the function is called into an object, the table ALLTRANSIENTS will also be saved to an object in the MATLAB workspace. If users prefer to analyze group or session means/differences in MATLAB, this option should be used. NOTE: In the exported csv file and output table, each transient is in a separate row. ID variables such as Subject or Session IDs will be added to the first few columns of every transient row. Code Example: Exporting all transients for each session into one table with added ID variables for Subject, Treatment Number, and Injection Type.","title":"Function: exportSessionTransients"},{"location":"userguide/userguide/","text":"PASTa User Guide This user guide is meant to serve as a detailed step-by-step practical guide through preparing, processing, and analyzing fiber photometry data with the PASTa protocol. Each section includes descriptions of each step, provides examples of fiber photometry recordings to show the effect on the data, and provides details on the required functions. For specific function troubleshooting, see the Function Documentation page.","title":"User Guide"},{"location":"userguide/userguide/#pasta-user-guide","text":"This user guide is meant to serve as a detailed step-by-step practical guide through preparing, processing, and analyzing fiber photometry data with the PASTa protocol. Each section includes descriptions of each step, provides examples of fiber photometry recordings to show the effect on the data, and provides details on the required functions. For specific function troubleshooting, see the Function Documentation page.","title":"PASTa User Guide"}]}